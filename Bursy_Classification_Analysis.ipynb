{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8164b3a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:24.158753Z",
     "start_time": "2021-12-05T21:32:24.156442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created on Sat Dec 09:00:12 2021\n",
      "\n",
      "@author: Katharina Sabrina bursy\n",
      "\n",
      "Machine Learning - DAT-5303 - BMBAN2\n",
      "Classification Model Development \n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Created on Sat Dec 09:00:12 2021\n",
    "\n",
    "@author: Katharina Sabrina bursy\n",
    "\n",
    "Machine Learning - DAT-5303 - BMBAN2\n",
    "Classification Model Development \n",
    "    \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3681f3d8",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e2b9cf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:24.161572Z",
     "start_time": "2021-12-05T21:32:24.159946Z"
    }
   },
   "outputs": [],
   "source": [
    "#import time for display of hoe long the code takes at the end\n",
    "import time \n",
    "start_time=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bada783a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:25.829823Z",
     "start_time": "2021-12-05T21:32:24.164166Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas            as pd                       # data science essentials\n",
    "import matplotlib.pyplot as plt                      # data visualization\n",
    "import seaborn           as sns                      # enhanced data viz\n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression\n",
    "import statsmodels.formula.api as smf                # logistic regression\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score            # auc score\n",
    "from sklearn.neighbors import KNeighborsClassifier   # KNN for classification\n",
    "from sklearn.neighbors import KNeighborsRegressor    # KNN for regression\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "\n",
    "# new packages\n",
    "from sklearn.model_selection import RandomizedSearchCV     # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer              # customizable scorer\n",
    "# new tools\n",
    "from sklearn.ensemble import RandomForestClassifier     # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5336bcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.288247Z",
     "start_time": "2021-12-05T21:32:25.830970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>culture</th>\n",
       "      <th>dateOfBirth</th>\n",
       "      <th>mother</th>\n",
       "      <th>father</th>\n",
       "      <th>heir</th>\n",
       "      <th>house</th>\n",
       "      <th>spouse</th>\n",
       "      <th>book1_A_Game_Of_Thrones</th>\n",
       "      <th>book2_A_Clash_Of_Kings</th>\n",
       "      <th>book3_A_Storm_Of_Swords</th>\n",
       "      <th>book4_A_Feast_For_Crows</th>\n",
       "      <th>book5_A_Dance_with_Dragons</th>\n",
       "      <th>isAliveMother</th>\n",
       "      <th>isAliveFather</th>\n",
       "      <th>isAliveHeir</th>\n",
       "      <th>isAliveSpouse</th>\n",
       "      <th>isMarried</th>\n",
       "      <th>isNoble</th>\n",
       "      <th>age</th>\n",
       "      <th>numDeadRelations</th>\n",
       "      <th>popularity</th>\n",
       "      <th>isAlive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Viserys II Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rhaenyra Targaryen</td>\n",
       "      <td>Daemon Targaryen</td>\n",
       "      <td>Aegon IV Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>0.605351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Walder Frey</td>\n",
       "      <td>Lord of the Crossing</td>\n",
       "      <td>Rivermen</td>\n",
       "      <td>208.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Frey</td>\n",
       "      <td>Perra Royce</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Addison Hill</td>\n",
       "      <td>Ser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Swyft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.267559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Aemma Arryn</td>\n",
       "      <td>Queen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Arryn</td>\n",
       "      <td>Viserys I Targaryen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sylva Santagar</td>\n",
       "      <td>Greenstone</td>\n",
       "      <td>Dornish</td>\n",
       "      <td>276.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Santagar</td>\n",
       "      <td>Eldon Estermont</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No                  name                 title   culture  dateOfBirth              mother            father                heir           house               spouse  book1_A_Game_Of_Thrones  book2_A_Clash_Of_Kings  book3_A_Storm_Of_Swords  book4_A_Feast_For_Crows  book5_A_Dance_with_Dragons  isAliveMother  isAliveFather  isAliveHeir  isAliveSpouse  isMarried  isNoble   age  numDeadRelations  popularity  isAlive\n",
       "0     1  Viserys II Targaryen                   NaN       NaN          NaN  Rhaenyra Targaryen  Daemon Targaryen  Aegon IV Targaryen             NaN                  NaN                        0                       0                        0                        0                           0            1.0            0.0          0.0            NaN          0        0   NaN                11    0.605351        0\n",
       "1     2           Walder Frey  Lord of the Crossing  Rivermen        208.0                 NaN               NaN                 NaN      House Frey          Perra Royce                        1                       1                        1                        1                           1            NaN            NaN          NaN            1.0          1        1  97.0                 1    0.896321        1\n",
       "2     3          Addison Hill                   Ser       NaN          NaN                 NaN               NaN                 NaN     House Swyft                  NaN                        0                       0                        0                        1                           0            NaN            NaN          NaN            NaN          0        1   NaN                 0    0.267559        1\n",
       "3     4           Aemma Arryn                 Queen       NaN         82.0                 NaN               NaN                 NaN     House Arryn  Viserys I Targaryen                        0                       0                        0                        0                           0            NaN            NaN          NaN            0.0          1        1  23.0                 0    0.183946        0\n",
       "4     5        Sylva Santagar            Greenstone   Dornish        276.0                 NaN               NaN                 NaN  House Santagar      Eldon Estermont                        0                       0                        0                        1                           0            NaN            NaN          NaN            1.0          1        1  29.0                 0    0.043478        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the file and display it\n",
    "file = \"./GOT_character_predictions.xlsx\"\n",
    "GOT= pd.read_excel(io=file)\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "GOT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71b01463",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.296867Z",
     "start_time": "2021-12-05T21:32:26.289203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1946 entries, 0 to 1945\n",
      "Data columns (total 25 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   S.No                        1946 non-null   int64  \n",
      " 1   name                        1946 non-null   object \n",
      " 2   title                       938 non-null    object \n",
      " 3   culture                     677 non-null    object \n",
      " 4   dateOfBirth                 433 non-null    float64\n",
      " 5   mother                      21 non-null     object \n",
      " 6   father                      26 non-null     object \n",
      " 7   heir                        23 non-null     object \n",
      " 8   house                       1519 non-null   object \n",
      " 9   spouse                      276 non-null    object \n",
      " 10  book1_A_Game_Of_Thrones     1946 non-null   int64  \n",
      " 11  book2_A_Clash_Of_Kings      1946 non-null   int64  \n",
      " 12  book3_A_Storm_Of_Swords     1946 non-null   int64  \n",
      " 13  book4_A_Feast_For_Crows     1946 non-null   int64  \n",
      " 14  book5_A_Dance_with_Dragons  1946 non-null   int64  \n",
      " 15  isAliveMother               21 non-null     float64\n",
      " 16  isAliveFather               26 non-null     float64\n",
      " 17  isAliveHeir                 23 non-null     float64\n",
      " 18  isAliveSpouse               276 non-null    float64\n",
      " 19  isMarried                   1946 non-null   int64  \n",
      " 20  isNoble                     1946 non-null   int64  \n",
      " 21  age                         433 non-null    float64\n",
      " 22  numDeadRelations            1946 non-null   int64  \n",
      " 23  popularity                  1946 non-null   float64\n",
      " 24  isAlive                     1946 non-null   int64  \n",
      "dtypes: float64(7), int64(10), object(8)\n",
      "memory usage: 380.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#check for missing values in the dataset\n",
    "GOT.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc58f02f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.301049Z",
     "start_time": "2021-12-05T21:32:26.298485Z"
    }
   },
   "outputs": [],
   "source": [
    "GOT=GOT.rename(columns={'S.No':'Order'})\n",
    "#renaming the column since it gave issues putting it with a dot in regression or other\n",
    "#not that the order has any impact anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e08a2446",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.303585Z",
     "start_time": "2021-12-05T21:32:26.302153Z"
    }
   },
   "outputs": [],
   "source": [
    "#Used variable that I did not want in the dataset later on\n",
    "# GOT['numDeadRelations'].value_counts()\n",
    "# GOT['D_numDeadRelations']=0\n",
    "# for index, value in GOT.iterrows():\n",
    "#     if GOT.loc[index, 'numDeadRelations'] ==0:\n",
    "#         GOT.loc[index, 'D_numDeadRelations'] = 1\n",
    "# GOT['D_numDeadRelations'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f126f6c8",
   "metadata": {},
   "source": [
    "# Missing Values\n",
    "Considering the high amount of missing data in the set, we created categories that says\n",
    "has an unknown value=1\n",
    "does have a value=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78136719",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.308580Z",
     "start_time": "2021-12-05T21:32:26.304257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1925\n",
       "0      21\n",
       "Name: mother_unknown, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a missing value flag for mother\n",
    "GOT['mother_unknown'] = GOT.loc[:, 'mother'].isnull().astype(int)\n",
    "GOT['mother_unknown'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eadffb3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.313991Z",
     "start_time": "2021-12-05T21:32:26.309563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1920\n",
       "0      26\n",
       "Name: father_unknown, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a missing value flag for father\n",
    "GOT['father_unknown'] = GOT.loc[:, 'father'].isnull().astype(int)\n",
    "GOT['father_unknown'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2503dcfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.319130Z",
     "start_time": "2021-12-05T21:32:26.314960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1519\n",
       "1     427\n",
       "Name: house_unknown, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a missing value flag for house\n",
    "GOT['house_unknown']= GOT.loc[:, 'house'].isnull().astype(int)\n",
    "GOT['house_unknown'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f85087c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.323910Z",
     "start_time": "2021-12-05T21:32:26.319903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1269\n",
       "0     677\n",
       "Name: culture_unknown, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a missing value flag for culture\n",
    "GOT['culture_unknown']= GOT.loc[:, 'culture'].isnull().astype(int)\n",
    "GOT['culture_unknown'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f30086",
   "metadata": {},
   "source": [
    "group the top 10 and use the others as others\n",
    "use gender guesser for some values,might give some more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "718559dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.330218Z",
     "start_time": "2021-12-05T21:32:26.326245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1008\n",
       "0     938\n",
       "Name: title_unknown, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a missing value flag for title\n",
    "GOT['title_unknown']= GOT.loc[:, 'title'].isnull().astype(int)\n",
    "GOT['title_unknown'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef9a4cc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.334881Z",
     "start_time": "2021-12-05T21:32:26.330985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1923\n",
       "0      23\n",
       "Name: heir_unknown, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a missing value flag for heir\n",
    "GOT['heir_unknown']= GOT.loc[:, 'heir'].isnull().astype(int)\n",
    "GOT['heir_unknown'].value_counts() #less uselful because not big enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4f87dad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.339681Z",
     "start_time": "2021-12-05T21:32:26.335816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1670\n",
       "0     276\n",
       "Name: spouse_unknown, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a missing value flag for spouse\n",
    "GOT['spouse_unknown'] = GOT.loc[:, 'spouse'].isnull().astype(int)\n",
    "GOT['spouse_unknown'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b66720c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.344565Z",
     "start_time": "2021-12-05T21:32:26.340619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1513\n",
       "0     433\n",
       "Name: age_unknown, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a missing value flag for age\n",
    "GOT['age_unknown'] = GOT.loc[:, 'age'].isnull().astype(int)\n",
    "GOT['age_unknown'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef22459a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.349303Z",
     "start_time": "2021-12-05T21:32:26.345427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1925\n",
       "0      21\n",
       "Name: isAliveMother_unknown, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a missing value flag for mother alive\n",
    "GOT['isAliveMother_unknown'] = GOT.loc[:, 'isAliveMother'].isnull().astype(int)\n",
    "GOT['isAliveMother_unknown'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af99a5d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.354620Z",
     "start_time": "2021-12-05T21:32:26.350110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1920\n",
       "0      26\n",
       "Name: isAliveFather_unknown, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a missing value flag for father alive\n",
    "GOT['isAliveFather_unknown'] = GOT.loc[:, 'isAliveFather'].isnull().astype(int)\n",
    "GOT['isAliveFather_unknown'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30a8d741",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.359521Z",
     "start_time": "2021-12-05T21:32:26.355553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1923\n",
       "0      23\n",
       "Name: isAliveHeir_unknown, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a missing value flag for heir alive\n",
    "GOT['isAliveHeir_unknown'] = GOT.loc[:, 'isAliveHeir'].isnull().astype(int)\n",
    "GOT['isAliveHeir_unknown'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faf385cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.365300Z",
     "start_time": "2021-12-05T21:32:26.360444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1670\n",
       "0     276\n",
       "Name: isAliveSpouse_unknown, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a missing value flag for spouse alive\n",
    "GOT['isAliveSpouse_unknown'] = GOT.loc[:, 'isAliveSpouse'].isnull().astype(int)\n",
    "GOT['isAliveSpouse_unknown'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3af48b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.371342Z",
     "start_time": "2021-12-05T21:32:26.366441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1920\n",
       "0      21\n",
       "1       5\n",
       "Name: isAliveParent_unknown, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a missing value flag for parent alive\n",
    "GOT['isAliveParent_unknown'] = GOT.loc[:, 'isAliveMother'].isnull().astype(int)+GOT.loc[:, 'isAliveFather'].isnull().astype(int)\n",
    "GOT['isAliveParent_unknown'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53e66498",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.496171Z",
     "start_time": "2021-12-05T21:32:26.372557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1644\n",
       "1     302\n",
       "Name: isAliveFamily_unknown, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if it makes sense that the whole family is alive or not\n",
    "#if one does have an \n",
    "GOT['isAliveFamily_unknown']=0\n",
    "for index, value in GOT.iterrows():\n",
    "    if GOT.loc[index, 'isAliveMother_unknown'] ==0 or GOT.loc[index, 'isAliveFather_unknown'] ==0\\\n",
    "    or GOT.loc[index, 'isAliveSpouse_unknown'] ==0:\n",
    "        GOT.loc[index, 'isAliveFamily_unknown'] = 1\n",
    "GOT['isAliveFamily_unknown'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f53d6bca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.653256Z",
     "start_time": "2021-12-05T21:32:26.497308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1250\n",
       "1     696\n",
       "Name: familiarity_mother, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOT['familiarity_mother']=0\n",
    "for index, value in GOT.iterrows():\n",
    "    if GOT.loc[index, 'mother_unknown'] ==0 or GOT.loc[index, 'culture_unknown'] ==0:\n",
    "        GOT.loc[index, 'familiarity_mother'] = 1\n",
    "GOT['familiarity_mother'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b898cc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:26.810604Z",
     "start_time": "2021-12-05T21:32:26.654228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1263\n",
       "1     683\n",
       "Name: familiarity_mother_2, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOT['familiarity_mother_2']=0\n",
    "for index, value in GOT.iterrows():\n",
    "    if GOT.loc[index, 'isAliveMother'] ==0 or GOT.loc[index, 'culture_unknown'] ==0:\n",
    "        GOT.loc[index, 'familiarity_mother_2'] = 1\n",
    "GOT['familiarity_mother_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c60a63a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:27.069895Z",
     "start_time": "2021-12-05T21:32:26.811715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1540\n",
       "0     406\n",
       "Name: familiarity_father, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOT['familiarity_father']=0\n",
    "for index, value in GOT.iterrows():\n",
    "    if GOT.loc[index, 'isAliveFather'] ==0 or GOT.loc[index, 'house_unknown'] ==0:\n",
    "        GOT.loc[index, 'familiarity_father'] = 1\n",
    "GOT['familiarity_father'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe872cc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:27.331415Z",
     "start_time": "2021-12-05T21:32:27.070946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1545\n",
       "0     401\n",
       "Name: familiarity_father_2, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOT['familiarity_father_2']=0\n",
    "for index, value in GOT.iterrows():\n",
    "    if GOT.loc[index, 'father_unknown'] ==0 or GOT.loc[index, 'house_unknown'] ==0:\n",
    "        GOT.loc[index, 'familiarity_father_2'] = 1\n",
    "GOT['familiarity_father_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b7041a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:27.515084Z",
     "start_time": "2021-12-05T21:32:27.332518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1049\n",
       "1     897\n",
       "Name: nobel_real, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a missing value flag for carat\n",
    "GOT['nobel_real'] = 0\n",
    "for index, value in GOT.iterrows():\n",
    "    if GOT.loc[index, 'title_unknown'] ==0 and GOT.loc[index, 'isNoble'] ==1:\n",
    "        GOT.loc[index, 'nobel_real'] = 1\n",
    "GOT['nobel_real'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e314c6da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:27.518857Z",
     "start_time": "2021-12-05T21:32:27.516088Z"
    }
   },
   "outputs": [],
   "source": [
    "GOT['popularity_survive'] = GOT['popularity'] + GOT['numDeadRelations'] \n",
    "#GOT['popularity_survive'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adf345dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:27.677330Z",
     "start_time": "2021-12-05T21:32:27.519792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1259\n",
       "1     687\n",
       "Name: heir_survive, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOT['heir_survive'] = 0\n",
    "for index, value in GOT.iterrows():\n",
    "    if GOT.loc[index, 'isAliveFather'] ==1 or GOT.loc[index, 'familiarity_mother_2'] ==1:\n",
    "        GOT.loc[index, 'heir_survive'] = 1\n",
    "GOT['heir_survive'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d6833bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:27.685671Z",
     "start_time": "2021-12-05T21:32:27.678371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000     457\n",
       "0.016722      80\n",
       "0.013378      79\n",
       "0.010033      70\n",
       "0.023411      67\n",
       "0.020067      60\n",
       "0.026756      58\n",
       "0.006689      55\n",
       "0.043478      37\n",
       "0.033445      37\n",
       "0.030100      36\n",
       "0.003344      35\n",
       "0.050167      29\n",
       "0.036789      28\n",
       "0.046823      27\n",
       "0.040134      25\n",
       "0.063545      23\n",
       "0.060201      23\n",
       "0.070234      21\n",
       "0.053512      20\n",
       "0.073579      19\n",
       "0.076923      18\n",
       "0.066890      18\n",
       "0.086957      18\n",
       "0.080268      16\n",
       "0.056856      16\n",
       "0.140468      14\n",
       "0.130435      13\n",
       "0.083612      13\n",
       "0.127090      11\n",
       "0.090301      11\n",
       "0.103679      11\n",
       "0.137124      11\n",
       "0.133779      10\n",
       "0.013378      10\n",
       "0.107023      10\n",
       "0.160535       8\n",
       "0.093645       8\n",
       "0.143813       8\n",
       "0.020067       8\n",
       "0.016722       8\n",
       "0.100334       7\n",
       "0.006689       7\n",
       "0.120401       7\n",
       "0.147157       6\n",
       "0.123746       6\n",
       "0.026756       6\n",
       "0.003344       6\n",
       "0.163880       6\n",
       "0.046823       6\n",
       "0.110368       6\n",
       "0.153846       6\n",
       "0.167224       5\n",
       "0.113712       5\n",
       "0.096990       5\n",
       "0.043478       4\n",
       "0.086957       4\n",
       "0.187291       4\n",
       "0.096990       4\n",
       "0.157191       4\n",
       "0.040134       4\n",
       "0.023411       4\n",
       "0.063545       4\n",
       "0.177258       4\n",
       "0.100334       3\n",
       "0.130435       3\n",
       "0.036789       3\n",
       "0.244147       3\n",
       "0.010033       3\n",
       "0.354515       3\n",
       "0.050167       3\n",
       "0.117057       3\n",
       "0.197324       3\n",
       "5.000000       3\n",
       "0.173913       3\n",
       "0.230769       3\n",
       "1.103679       3\n",
       "6.000000       3\n",
       "8.000000       3\n",
       "0.200669       3\n",
       "0.066890       3\n",
       "7.000000       3\n",
       "0.076923       3\n",
       "0.290970       3\n",
       "0.270903       3\n",
       "0.060201       2\n",
       "0.150502       2\n",
       "1.063545       2\n",
       "0.073579       2\n",
       "0.190635       2\n",
       "0.357860       2\n",
       "1.137124       2\n",
       "0.414716       2\n",
       "0.364548       2\n",
       "0.163880       2\n",
       "1.170569       2\n",
       "0.237458       2\n",
       "1.107023       2\n",
       "0.180602       2\n",
       "0.217391       2\n",
       "0.170569       2\n",
       "1.080268       2\n",
       "0.327759       2\n",
       "0.210702       2\n",
       "1.117057       2\n",
       "0.220736       2\n",
       "11.000000      2\n",
       "0.183946       2\n",
       "0.227425       2\n",
       "0.127090       2\n",
       "0.618729       2\n",
       "0.120401       2\n",
       "0.056856       2\n",
       "0.070234       2\n",
       "0.183946       2\n",
       "4.739130       2\n",
       "6.331104       1\n",
       "1.836120       1\n",
       "2.086957       1\n",
       "7.695652       1\n",
       "1.451505       1\n",
       "0.551839       1\n",
       "0.638796       1\n",
       "1.461538       1\n",
       "0.224080       1\n",
       "2.083612       1\n",
       "0.394649       1\n",
       "1.100334       1\n",
       "0.204013       1\n",
       "0.525084       1\n",
       "8.655518       1\n",
       "0.311037       1\n",
       "4.605351       1\n",
       "0.505017       1\n",
       "5.668896       1\n",
       "0.254181       1\n",
       "16.000000      1\n",
       "5.401338       1\n",
       "1.000000       1\n",
       "9.501672       1\n",
       "1.969900       1\n",
       "0.709030       1\n",
       "0.344482       1\n",
       "0.257525       1\n",
       "0.207358       1\n",
       "0.277592       1\n",
       "5.341137       1\n",
       "4.458194       1\n",
       "0.193980       1\n",
       "11.605351      1\n",
       "1.384615       1\n",
       "13.000000      1\n",
       "1.076923       1\n",
       "0.397993       1\n",
       "1.695652       1\n",
       "0.374582       1\n",
       "6.167224       1\n",
       "0.535117       1\n",
       "8.551839       1\n",
       "6.217391       1\n",
       "1.096990       1\n",
       "0.217391       1\n",
       "0.571906       1\n",
       "0.277592       1\n",
       "0.347826       1\n",
       "0.367893       1\n",
       "1.123746       1\n",
       "5.227425       1\n",
       "11.799331      1\n",
       "2.438127       1\n",
       "2.665552       1\n",
       "2.170569       1\n",
       "0.351171       1\n",
       "6.150502       1\n",
       "4.153846       1\n",
       "5.836120       1\n",
       "4.705686       1\n",
       "4.869565       1\n",
       "0.150502       1\n",
       "0.297659       1\n",
       "2.147157       1\n",
       "1.173913       1\n",
       "4.140468       1\n",
       "1.140468       1\n",
       "1.979933       1\n",
       "4.230769       1\n",
       "3.000000       1\n",
       "0.321070       1\n",
       "8.321070       1\n",
       "0.267559       1\n",
       "2.371237       1\n",
       "1.230769       1\n",
       "4.043478       1\n",
       "1.397993       1\n",
       "0.719064       1\n",
       "5.270903       1\n",
       "0.511706       1\n",
       "11.622074      1\n",
       "5.277592       1\n",
       "5.137124       1\n",
       "0.371237       1\n",
       "7.227425       1\n",
       "6.140468       1\n",
       "7.137124       1\n",
       "0.280936       1\n",
       "0.494983       1\n",
       "5.658863       1\n",
       "0.424749       1\n",
       "5.230769       1\n",
       "1.020067       1\n",
       "0.234114       1\n",
       "1.073579       1\n",
       "0.484950       1\n",
       "0.214047       1\n",
       "1.043478       1\n",
       "0.113712       1\n",
       "1.046823       1\n",
       "0.103679       1\n",
       "0.033445       1\n",
       "1.056856       1\n",
       "0.260870       1\n",
       "10.765886      1\n",
       "7.518395       1\n",
       "0.247492       1\n",
       "10.093645      1\n",
       "0.267559       1\n",
       "0.431438       1\n",
       "0.193980       1\n",
       "0.705686       1\n",
       "4.000000       1\n",
       "12.220736      1\n",
       "3.096990       1\n",
       "0.143813       1\n",
       "1.277592       1\n",
       "10.244147      1\n",
       "1.170569       1\n",
       "1.113712       1\n",
       "0.969900       1\n",
       "7.759197       1\n",
       "8.625418       1\n",
       "5.571906       1\n",
       "3.622074       1\n",
       "4.267559       1\n",
       "3.474916       1\n",
       "0.157191       1\n",
       "0.284281       1\n",
       "5.488294       1\n",
       "10.000000      1\n",
       "6.498328       1\n",
       "2.160535       1\n",
       "0.364548       1\n",
       "2.096990       1\n",
       "0.561873       1\n",
       "0.250836       1\n",
       "1.722408       1\n",
       "0.117057       1\n",
       "5.478261       1\n",
       "2.127090       1\n",
       "5.354515       1\n",
       "1.856187       1\n",
       "0.745819       1\n",
       "0.434783       1\n",
       "5.561873       1\n",
       "1.377926       1\n",
       "5.772575       1\n",
       "0.287625       1\n",
       "0.250836       1\n",
       "0.220736       1\n",
       "0.471572       1\n",
       "0.274247       1\n",
       "0.377926       1\n",
       "0.334448       1\n",
       "5.036789       1\n",
       "1.896321       1\n",
       "0.314381       1\n",
       "0.107023       1\n",
       "1.083612       1\n",
       "0.170569       1\n",
       "1.023411       1\n",
       "0.137124       1\n",
       "1.080268       1\n",
       "1.120401       1\n",
       "4.167224       1\n",
       "0.080268       1\n",
       "4.210702       1\n",
       "0.147157       1\n",
       "4.207358       1\n",
       "4.311037       1\n",
       "9.000000       1\n",
       "1.307692       1\n",
       "4.210702       1\n",
       "Name: heir_survive_2, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOT['heir_survive_2'] = GOT['popularity_survive']*GOT['familiarity_father']\n",
    "GOT['heir_survive_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41947140",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:27.698783Z",
     "start_time": "2021-12-05T21:32:27.690862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.016722     80\n",
       "1.013378     79\n",
       "1.010033     70\n",
       "1.023411     67\n",
       "1.020067     60\n",
       "1.026756     58\n",
       "1.006689     55\n",
       "1.000000     51\n",
       "0.006689     48\n",
       "0.013378     41\n",
       "0.003344     41\n",
       "1.033445     37\n",
       "1.043478     37\n",
       "1.030100     36\n",
       "1.003344     35\n",
       "0.016722     33\n",
       "0.000000     33\n",
       "0.010033     31\n",
       "1.050167     29\n",
       "1.036789     28\n",
       "1.046823     27\n",
       "1.040134     25\n",
       "1.063545     23\n",
       "1.060201     23\n",
       "1.070234     21\n",
       "1.053512     20\n",
       "1.073579     19\n",
       "1.066890     18\n",
       "0.020067     18\n",
       "1.076923     18\n",
       "1.086957     18\n",
       "1.080268     16\n",
       "1.056856     16\n",
       "0.023411     14\n",
       "1.140468     14\n",
       "1.130435     14\n",
       "1.083612     13\n",
       "1.090301     11\n",
       "1.127090     11\n",
       "1.103679     11\n",
       "1.137124     11\n",
       "1.013378     10\n",
       "0.026756     10\n",
       "1.133779     10\n",
       "1.107023     10\n",
       "0.040134      9\n",
       "1.020067      8\n",
       "1.093645      8\n",
       "1.143813      8\n",
       "1.016722      8\n",
       "0.030100      8\n",
       "1.160535      8\n",
       "1.006689      7\n",
       "1.120401      7\n",
       "1.100334      7\n",
       "1.026756      6\n",
       "1.046823      6\n",
       "1.003344      6\n",
       "0.036789      6\n",
       "1.110368      6\n",
       "1.153846      6\n",
       "0.043478      6\n",
       "0.050167      6\n",
       "1.163880      6\n",
       "1.147157      6\n",
       "1.123746      6\n",
       "0.010033      5\n",
       "0.056856      5\n",
       "6.000000      5\n",
       "1.113712      5\n",
       "1.096990      5\n",
       "1.167224      5\n",
       "1.096990      4\n",
       "1.086957      4\n",
       "0.003344      4\n",
       "1.157191      4\n",
       "1.023411      4\n",
       "1.040134      4\n",
       "0.013378      4\n",
       "0.033445      4\n",
       "1.043478      4\n",
       "1.063545      4\n",
       "1.187291      4\n",
       "1.177258      4\n",
       "0.063545      3\n",
       "1.130435      3\n",
       "0.103679      3\n",
       "1.036789      3\n",
       "0.046823      3\n",
       "1.197324      3\n",
       "1.244147      3\n",
       "1.100334      3\n",
       "1.354515      3\n",
       "1.010033      3\n",
       "8.000000      3\n",
       "1.173913      3\n",
       "0.016722      3\n",
       "1.066890      3\n",
       "0.006689      3\n",
       "1.117057      3\n",
       "7.000000      3\n",
       "9.000000      3\n",
       "1.230769      3\n",
       "0.076923      3\n",
       "1.076923      3\n",
       "1.290970      3\n",
       "2.103679      3\n",
       "1.270903      3\n",
       "0.020067      3\n",
       "0.053512      3\n",
       "1.200669      3\n",
       "1.050167      3\n",
       "1.183946      2\n",
       "1.073579      2\n",
       "1.190635      2\n",
       "2.170569      2\n",
       "1.180602      2\n",
       "2.107023      2\n",
       "0.120401      2\n",
       "1.237458      2\n",
       "1.060201      2\n",
       "1.364548      2\n",
       "0.127090      2\n",
       "1.150502      2\n",
       "1.217391      2\n",
       "1.414716      2\n",
       "1.163880      2\n",
       "1.357860      2\n",
       "2.137124      2\n",
       "5.739130      2\n",
       "0.080268      2\n",
       "1.287625      2\n",
       "1.183946      2\n",
       "1.210702      2\n",
       "1.220736      2\n",
       "1.127090      2\n",
       "1.618729      2\n",
       "0.143813      2\n",
       "0.060201      2\n",
       "2.117057      2\n",
       "1.327759      2\n",
       "0.083612      2\n",
       "0.066890      2\n",
       "1.170569      2\n",
       "12.000000     2\n",
       "2.080268      2\n",
       "2.063545      2\n",
       "1.120401      2\n",
       "0.023411      2\n",
       "1.070234      2\n",
       "0.183946      2\n",
       "1.056856      2\n",
       "1.227425      2\n",
       "0.086957      2\n",
       "6.668896      1\n",
       "6.341137      1\n",
       "3.083612      1\n",
       "5.605351      1\n",
       "1.254181      1\n",
       "2.461538      1\n",
       "6.401338      1\n",
       "0.434783      1\n",
       "0.217391      1\n",
       "1.551839      1\n",
       "2.836120      1\n",
       "1.638796      1\n",
       "0.444816      1\n",
       "2.451505      1\n",
       "7.331104      1\n",
       "1.511706      1\n",
       "1.204013      1\n",
       "1.525084      1\n",
       "2.100334      1\n",
       "1.709030      1\n",
       "1.505017      1\n",
       "10.501672     1\n",
       "17.000000     1\n",
       "2.000000      1\n",
       "0.117057      1\n",
       "1.207358      1\n",
       "2.969900      1\n",
       "1.344482      1\n",
       "7.441472      1\n",
       "1.257525      1\n",
       "1.277592      1\n",
       "5.458194      1\n",
       "9.655518      1\n",
       "3.086957      1\n",
       "8.695652      1\n",
       "1.311037      1\n",
       "1.224080      1\n",
       "12.605351     1\n",
       "1.394649      1\n",
       "1.193980      1\n",
       "5.153846      1\n",
       "14.000000     1\n",
       "7.150502      1\n",
       "2.076923      1\n",
       "1.397993      1\n",
       "2.695652      1\n",
       "1.374582      1\n",
       "7.167224      1\n",
       "1.535117      1\n",
       "9.551839      1\n",
       "7.217391      1\n",
       "2.096990      1\n",
       "1.217391      1\n",
       "0.140468      1\n",
       "1.571906      1\n",
       "1.277592      1\n",
       "1.347826      1\n",
       "1.367893      1\n",
       "2.123746      1\n",
       "6.227425      1\n",
       "12.799331     1\n",
       "5.558528      1\n",
       "3.438127      1\n",
       "3.665552      1\n",
       "3.170569      1\n",
       "0.046823      1\n",
       "1.351171      1\n",
       "0.214047      1\n",
       "0.290970      1\n",
       "5.705686      1\n",
       "5.230769      1\n",
       "2.384615      1\n",
       "6.836120      1\n",
       "0.030100      1\n",
       "5.869565      1\n",
       "1.150502      1\n",
       "1.297659      1\n",
       "3.147157      1\n",
       "2.173913      1\n",
       "0.709030      1\n",
       "5.140468      1\n",
       "2.140468      1\n",
       "2.979933      1\n",
       "4.000000      1\n",
       "0.899666      1\n",
       "0.227425      1\n",
       "1.321070      1\n",
       "9.321070      1\n",
       "1.267559      1\n",
       "3.371237      1\n",
       "2.230769      1\n",
       "5.043478      1\n",
       "2.397993      1\n",
       "1.719064      1\n",
       "6.270903      1\n",
       "6.277592      1\n",
       "12.622074     1\n",
       "1.371237      1\n",
       "2.056856      1\n",
       "6.488294      1\n",
       "2.003344      1\n",
       "8.518395      1\n",
       "8.227425      1\n",
       "11.765886     1\n",
       "7.140468      1\n",
       "8.137124      1\n",
       "0.100334      1\n",
       "1.280936      1\n",
       "1.494983      1\n",
       "6.658863      1\n",
       "0.073579      1\n",
       "1.424749      1\n",
       "6.230769      1\n",
       "0.237458      1\n",
       "0.043478      1\n",
       "2.020067      1\n",
       "1.234114      1\n",
       "2.073579      1\n",
       "1.484950      1\n",
       "1.214047      1\n",
       "2.043478      1\n",
       "1.113712      1\n",
       "0.063545      1\n",
       "2.046823      1\n",
       "11.093645     1\n",
       "4.474916      1\n",
       "0.260870      1\n",
       "5.267559      1\n",
       "1.267559      1\n",
       "1.431438      1\n",
       "5.678930      1\n",
       "1.193980      1\n",
       "1.705686      1\n",
       "5.000000      1\n",
       "13.220736     1\n",
       "4.096990      1\n",
       "1.143813      1\n",
       "2.277592      1\n",
       "11.244147     1\n",
       "0.244147      1\n",
       "0.026756      1\n",
       "2.170569      1\n",
       "0.033445      1\n",
       "0.090301      1\n",
       "2.113712      1\n",
       "1.969900      1\n",
       "8.759197      1\n",
       "15.675585     1\n",
       "9.625418      1\n",
       "6.571906      1\n",
       "4.622074      1\n",
       "1.103679      1\n",
       "1.033445      1\n",
       "1.250836      1\n",
       "2.307692      1\n",
       "1.471572      1\n",
       "11.000000     1\n",
       "1.220736      1\n",
       "7.498328      1\n",
       "3.160535      1\n",
       "1.364548      1\n",
       "0.204013      1\n",
       "3.096990      1\n",
       "1.561873      1\n",
       "1.250836      1\n",
       "2.722408      1\n",
       "1.117057      1\n",
       "6.478261      1\n",
       "3.127090      1\n",
       "6.354515      1\n",
       "2.856187      1\n",
       "0.160535      1\n",
       "1.745819      1\n",
       "1.434783      1\n",
       "6.561873      1\n",
       "2.377926      1\n",
       "6.772575      1\n",
       "0.254181      1\n",
       "1.377926      1\n",
       "10.000000     1\n",
       "2.896321      1\n",
       "5.311037      1\n",
       "1.260870      1\n",
       "1.157191      1\n",
       "1.247492      1\n",
       "0.170569      1\n",
       "1.284281      1\n",
       "1.274247      1\n",
       "1.334448      1\n",
       "6.036789      1\n",
       "6.137124      1\n",
       "1.314381      1\n",
       "1.107023      1\n",
       "2.083612      1\n",
       "0.070234      1\n",
       "1.170569      1\n",
       "2.023411      1\n",
       "1.137124      1\n",
       "2.080268      1\n",
       "2.120401      1\n",
       "5.167224      1\n",
       "1.080268      1\n",
       "5.210702      1\n",
       "1.147157      1\n",
       "5.207358      1\n",
       "5.210702      1\n",
       "Name: heir_survive_3, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOT['heir_survive_3'] = GOT['popularity_survive']+GOT['familiarity_father']\n",
    "GOT['heir_survive_3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a76636e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.014835Z",
     "start_time": "2021-12-05T21:32:27.699757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1946\n",
       "Name: heir_survive, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOT['alive_fam']=0\n",
    "for index, value in GOT.iterrows():\n",
    "    if GOT.loc[index, 'isAliveFather'] ==1 or GOT.loc[index, 'isAliveMother'] ==1 or GOT.loc[index, 'isAliveMother'] :\n",
    "        GOT.loc[index, 'heir_survive'] = 1\n",
    "GOT['heir_survive'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4daa669a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.020571Z",
     "start_time": "2021-12-05T21:32:28.015855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    663\n",
       "2    331\n",
       "3    286\n",
       "0    272\n",
       "5    212\n",
       "4    182\n",
       "Name: alive_books, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOT['alive_books']= GOT['book1_A_Game_Of_Thrones']+GOT['book2_A_Clash_Of_Kings']+ GOT['book3_A_Storm_Of_Swords']\\\n",
    "+GOT['book4_A_Feast_For_Crows']+GOT['book5_A_Dance_with_Dragons']\n",
    "GOT['alive_books'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ed95553",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.024021Z",
     "start_time": "2021-12-05T21:32:28.021549Z"
    }
   },
   "outputs": [],
   "source": [
    "GOT['alive_books_longest']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83867fbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.102795Z",
     "start_time": "2021-12-05T21:32:28.025010Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, value in GOT.iterrows():\n",
    "    if GOT.loc[index, 'alive_books'] ==5 :\n",
    "        GOT.loc[index, 'alive_books_longest'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd9374b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.107462Z",
     "start_time": "2021-12-05T21:32:28.103902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1734\n",
       "1     212\n",
       "Name: alive_books_longest, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOT['alive_books_longest'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f71d082",
   "metadata": {},
   "source": [
    "# Gender guesser\n",
    "\n",
    "Commented out for time reasons and hardcoded at the bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f5ca530",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.110522Z",
     "start_time": "2021-12-05T21:32:28.108487Z"
    }
   },
   "outputs": [],
   "source": [
    "# import random as rand # random number generation\n",
    "# # New! (may need to be downloaded)\n",
    "# import gender_guesser.detector as gender # guess gender based on (given) name\n",
    "# # setting random seed\n",
    "# rand.seed(a = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b8da051",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.113229Z",
     "start_time": "2021-12-05T21:32:28.111571Z"
    }
   },
   "outputs": [],
   "source": [
    "# # STEP 1: splitting names \n",
    "\n",
    "# # placeholder list\n",
    "# placeholder_lst = []\n",
    "\n",
    "# # looping over each email address\n",
    "# for index, col in GOT.iterrows():\n",
    "    \n",
    "#     # splitting name by the ' ' in the middle\n",
    "#     split_name = GOT.loc[index, 'name'].split(sep = ' ')\n",
    "    \n",
    "#     # appending placeholder_lst with the results\n",
    "#     placeholder_lst.append(split_name)\n",
    "    \n",
    "\n",
    "# # converting placeholder_lst into a DataFrame \n",
    "# name_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "\n",
    "# # displaying the results\n",
    "# name_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ac9beb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.115936Z",
     "start_time": "2021-12-05T21:32:28.114269Z"
    }
   },
   "outputs": [],
   "source": [
    "# #gender guesser needs the first column with the first name\n",
    "# #therefore we can drop the other columns\n",
    "# name_df=name_df.drop(5,axis=1)\n",
    "# name_df\n",
    "# name_df=name_df.drop(4,axis=1)\n",
    "# name_df\n",
    "# name_df=name_df.drop(3,axis=1)\n",
    "# name_df\n",
    "# name_df=name_df.drop(2,axis=1)\n",
    "# name_df\n",
    "# name_df=name_df.drop(1,axis=1)\n",
    "# name_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af9b16ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.118453Z",
     "start_time": "2021-12-05T21:32:28.116963Z"
    }
   },
   "outputs": [],
   "source": [
    "# # renaming column for easier use\n",
    "# name_df = name_df.rename(columns={name_df.columns[0]: 'First_name'})\n",
    "# name_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d40e868",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.120717Z",
     "start_time": "2021-12-05T21:32:28.119327Z"
    }
   },
   "outputs": [],
   "source": [
    "# GOT = pd.concat([GOT, name_df['First_name']],\n",
    "#                    axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c62c44b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.123397Z",
     "start_time": "2021-12-05T21:32:28.121550Z"
    }
   },
   "outputs": [],
   "source": [
    "# # guessing gender based on (given) name\n",
    "\n",
    "# # placeholder list\n",
    "# placeholder_lst=[]\n",
    "\n",
    "\n",
    "# # looping to guess gender\n",
    "# for name in GOT['First_name']:\n",
    "#     guess = gender.Detector().get_gender(name)\n",
    "#     print(guess)\n",
    "#     placeholder_lst.append(guess)\n",
    "\n",
    "\n",
    "# # converting list into a series\n",
    "# GOT['gender_guess'] = pd.Series(placeholder_lst)\n",
    "\n",
    "\n",
    "# # checking results\n",
    "# GOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2663e49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.125881Z",
     "start_time": "2021-12-05T21:32:28.124292Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for val in GOT['gender_guess']:\n",
    "#     print(f\"'{val}',\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "489055d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.219610Z",
     "start_time": "2021-12-05T21:32:28.127221Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "gender_guesser = ['unknown',\n",
    "'unknown',\n",
    "'andy',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'mostly_male',\n",
    "'mostly_male',\n",
    "'mostly_male',\n",
    "'mostly_male',\n",
    "'mostly_male',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'andy',\n",
    "'andy',\n",
    "'unknown',\n",
    "'andy',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'mostly_male',\n",
    "'male',\n",
    "'mostly_male',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'andy',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'andy',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'female',\n",
    "'female',\n",
    "'female',\n",
    "'female',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'female',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'andy',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'andy',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'mostly_female',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'female',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'male',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'female',\n",
    "'mostly_female',\n",
    "'female',\n",
    "'mostly_female',\n",
    "'mostly_female',\n",
    "'mostly_female',\n",
    "'mostly_female',\n",
    "'mostly_female',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'andy',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'mostly_male',\n",
    "'mostly_male',\n",
    "'mostly_male',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'andy',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'male',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "025009be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.223113Z",
     "start_time": "2021-12-05T21:32:28.220737Z"
    }
   },
   "outputs": [],
   "source": [
    "#match the hardcoded list to the dataframe\n",
    "GOT['gender_guess']=gender_guesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9934d588",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.227855Z",
     "start_time": "2021-12-05T21:32:28.224118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown          1385\n",
       "male              381\n",
       "female            125\n",
       "mostly_male        24\n",
       "mostly_female      21\n",
       "andy               10\n",
       "Name: gender_guess, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the values and if each categoryhas enough\n",
    "GOT['gender_guess'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5ca9f3",
   "metadata": {},
   "source": [
    "## M_gender & is_female\n",
    "if the gender is unknown flag it othewise 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "do this to avoid that some categories have a lov amount of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c763ab6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.433168Z",
     "start_time": "2021-12-05T21:32:28.228908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1385\n",
       "0     561\n",
       "Name: m_gender, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#simple loop to create the new variable \n",
    "GOT['m_gender']=0\n",
    "for index, value in GOT.iterrows():\n",
    "    if GOT.loc[index, 'gender_guess'] == 'unknown' :\n",
    "        GOT.loc[index, 'm_gender'] = 1\n",
    "GOT['m_gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d71f19f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.516792Z",
     "start_time": "2021-12-05T21:32:28.434199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1800\n",
       "1     146\n",
       "Name: is_female, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#simple loop to create the new variable \n",
    "#if the name is mostly female or female give it a one otherwise 0\n",
    "GOT['is_female']=0\n",
    "for index, value in GOT.iterrows():\n",
    "    if GOT.loc[index, 'gender_guess'] == 'female' or GOT.loc[index, 'gender_guess'] == 'mostly_female' :\n",
    "        GOT.loc[index, 'is_female'] = 1\n",
    "GOT['is_female'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedd3f9d",
   "metadata": {},
   "source": [
    "# Optimal neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cbca3ffd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.526910Z",
     "start_time": "2021-12-05T21:32:28.517925Z"
    }
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# optimal_neighbors\n",
    "########################################\n",
    "def optimal_neighbors(x_data,\n",
    "                      y_data,\n",
    "                      standardize = True,\n",
    "                      pct_test=0.10,\n",
    "                      seed=219,\n",
    "                      response_type='reg',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):\n",
    "    \"\"\"\n",
    "Exhaustively compute training and testing results for KNN across\n",
    "[1, max_neighbors]. Outputs the maximum test score and (by default) a\n",
    "visualization of the results.\n",
    "PARAMETERS\n",
    "----------\n",
    "x_data        : explanatory variable data\n",
    "y_data        : response variable\n",
    "standardize   : whether or not to standardize the x data, default True\n",
    "pct_test      : test size for training and validation from (0,1), default 0.25\n",
    "seed          : random seed to be used in algorithm, default 219\n",
    "response_type : type of neighbors algorithm to use, default 'reg'\n",
    "    Use 'reg' for regression (KNeighborsRegressor)\n",
    "    Use 'class' for classification (KNeighborsClassifier)\n",
    "max_neighbors : maximum number of neighbors in exhaustive search, default 20\n",
    "show_viz      : display or surpress k-neigbors visualization, default True\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "    if standardize == True:\n",
    "        # optionally standardizing x_data\n",
    "        scaler             = StandardScaler()\n",
    "        scaler.fit(x_data)\n",
    "        x_scaled           = scaler.transform(x_data)\n",
    "        x_scaled_df        = pd.DataFrame(x_scaled)\n",
    "        x_data             = x_scaled_df\n",
    "\n",
    "\n",
    "\n",
    "    # train-test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed)\n",
    "\n",
    "\n",
    "    # creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    \n",
    "    # setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(x_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(x_test, y_test))\n",
    "\n",
    "\n",
    "    # optionally displaying visualization\n",
    "    if show_viz == True:\n",
    "        # plotting the visualization\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "        plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"n_neighbors\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # returning optimal number of neighbors\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1\n",
    "\n",
    "\n",
    "########################################\n",
    "# visual_cm\n",
    "########################################\n",
    "def visual_cm(true_y, pred_y, labels = None):\n",
    "    \"\"\"\n",
    "Creates a visualization of a confusion matrix.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "true_y : true values for the response variable\n",
    "pred_y : predicted values for the response variable\n",
    "labels : , default None\n",
    "    \"\"\"\n",
    "    # visualizing the confusion matrix\n",
    "\n",
    "    # setting labels\n",
    "    lbls = labels\n",
    "    \n",
    "\n",
    "    # declaring a confusion matrix object\n",
    "    cm = confusion_matrix(y_true = true_y,\n",
    "                          y_pred = pred_y)\n",
    "\n",
    "\n",
    "    # heatmap\n",
    "    sns.heatmap(cm,\n",
    "                annot       = True,\n",
    "                xticklabels = lbls,\n",
    "                yticklabels = lbls,\n",
    "                cmap        = 'Blues',\n",
    "                fmt         = 'g')\n",
    "\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix of the Classifier')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ffcf676d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.543610Z",
     "start_time": "2021-12-05T21:32:28.527917Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isAlive                       1.00\n",
       "isAliveHeir                   0.38\n",
       "book4_A_Feast_For_Crows       0.27\n",
       "isAliveFather                 0.20\n",
       "isAliveSpouse                 0.17\n",
       "age_unknown                   0.15\n",
       "mother_unknown                0.14\n",
       "isAliveMother_unknown         0.14\n",
       "father_unknown                0.14\n",
       "isAliveFather_unknown         0.14\n",
       "isAliveParent_unknown         0.14\n",
       "isAliveHeir_unknown           0.13\n",
       "heir_unknown                  0.13\n",
       "age                           0.09\n",
       "isAliveSpouse_unknown         0.05\n",
       "spouse_unknown                0.05\n",
       "is_female                     0.05\n",
       "culture_unknown               0.04\n",
       "alive_books                   0.04\n",
       "title_unknown                 0.04\n",
       "house_unknown                 0.04\n",
       "book5_A_Dance_with_Dragons    0.03\n",
       "book3_A_Storm_Of_Swords       0.01\n",
       "alive_books_longest          -0.01\n",
       "m_gender                     -0.03\n",
       "isNoble                      -0.04\n",
       "isAliveMother                -0.04\n",
       "nobel_real                   -0.04\n",
       "familiarity_mother_2         -0.05\n",
       "isMarried                    -0.05\n",
       "familiarity_father           -0.07\n",
       "familiarity_mother           -0.07\n",
       "book2_A_Clash_Of_Kings       -0.07\n",
       "familiarity_father_2         -0.08\n",
       "dateOfBirth                  -0.09\n",
       "isAliveFamily_unknown        -0.09\n",
       "Order                        -0.13\n",
       "book1_A_Game_Of_Thrones      -0.15\n",
       "heir_survive_2               -0.18\n",
       "popularity                   -0.18\n",
       "numDeadRelations             -0.19\n",
       "popularity_survive           -0.20\n",
       "heir_survive_3               -0.21\n",
       "heir_survive                   NaN\n",
       "alive_fam                      NaN\n",
       "Name: isAlive, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initally check how the given variables are correlated to the y-variable\n",
    "df_corr = GOT.corr(method='pearson').round(2)\n",
    "\n",
    "df_corr['isAlive'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e57d6539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.548564Z",
     "start_time": "2021-12-05T21:32:28.544528Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.75\n",
       "0    0.25\n",
       "Name: isAlive, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chekc the y- variabe and how the value_counts are\n",
    "GOT.loc[ : ,'isAlive'].value_counts(normalize = True).round(decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0509e6",
   "metadata": {},
   "source": [
    "## Drop unnecessary variables with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "03d563c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.574267Z",
     "start_time": "2021-12-05T21:32:28.549520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>culture</th>\n",
       "      <th>dateOfBirth</th>\n",
       "      <th>mother</th>\n",
       "      <th>father</th>\n",
       "      <th>heir</th>\n",
       "      <th>house</th>\n",
       "      <th>spouse</th>\n",
       "      <th>book1_A_Game_Of_Thrones</th>\n",
       "      <th>book2_A_Clash_Of_Kings</th>\n",
       "      <th>book3_A_Storm_Of_Swords</th>\n",
       "      <th>book4_A_Feast_For_Crows</th>\n",
       "      <th>book5_A_Dance_with_Dragons</th>\n",
       "      <th>isAliveMother</th>\n",
       "      <th>isAliveFather</th>\n",
       "      <th>isAliveHeir</th>\n",
       "      <th>isAliveSpouse</th>\n",
       "      <th>isMarried</th>\n",
       "      <th>isNoble</th>\n",
       "      <th>age</th>\n",
       "      <th>numDeadRelations</th>\n",
       "      <th>popularity</th>\n",
       "      <th>isAlive</th>\n",
       "      <th>mother_unknown</th>\n",
       "      <th>father_unknown</th>\n",
       "      <th>house_unknown</th>\n",
       "      <th>culture_unknown</th>\n",
       "      <th>title_unknown</th>\n",
       "      <th>heir_unknown</th>\n",
       "      <th>spouse_unknown</th>\n",
       "      <th>age_unknown</th>\n",
       "      <th>isAliveMother_unknown</th>\n",
       "      <th>isAliveFather_unknown</th>\n",
       "      <th>isAliveHeir_unknown</th>\n",
       "      <th>isAliveSpouse_unknown</th>\n",
       "      <th>isAliveParent_unknown</th>\n",
       "      <th>isAliveFamily_unknown</th>\n",
       "      <th>familiarity_mother</th>\n",
       "      <th>familiarity_mother_2</th>\n",
       "      <th>familiarity_father</th>\n",
       "      <th>familiarity_father_2</th>\n",
       "      <th>nobel_real</th>\n",
       "      <th>popularity_survive</th>\n",
       "      <th>heir_survive</th>\n",
       "      <th>heir_survive_2</th>\n",
       "      <th>heir_survive_3</th>\n",
       "      <th>alive_fam</th>\n",
       "      <th>alive_books</th>\n",
       "      <th>alive_books_longest</th>\n",
       "      <th>gender_guess</th>\n",
       "      <th>m_gender</th>\n",
       "      <th>is_female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Viserys II Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rhaenyra Targaryen</td>\n",
       "      <td>Daemon Targaryen</td>\n",
       "      <td>Aegon IV Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>0.605351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.605351</td>\n",
       "      <td>1</td>\n",
       "      <td>11.605351</td>\n",
       "      <td>12.605351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Walder Frey</td>\n",
       "      <td>Lord of the Crossing</td>\n",
       "      <td>Rivermen</td>\n",
       "      <td>208.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Frey</td>\n",
       "      <td>Perra Royce</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.896321</td>\n",
       "      <td>1</td>\n",
       "      <td>1.896321</td>\n",
       "      <td>2.896321</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Addison Hill</td>\n",
       "      <td>Ser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Swyft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.267559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.267559</td>\n",
       "      <td>1</td>\n",
       "      <td>0.267559</td>\n",
       "      <td>1.267559</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>andy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Aemma Arryn</td>\n",
       "      <td>Queen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Arryn</td>\n",
       "      <td>Viserys I Targaryen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183946</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.183946</td>\n",
       "      <td>1</td>\n",
       "      <td>0.183946</td>\n",
       "      <td>1.183946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sylva Santagar</td>\n",
       "      <td>Greenstone</td>\n",
       "      <td>Dornish</td>\n",
       "      <td>276.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Santagar</td>\n",
       "      <td>Eldon Estermont</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1.043478</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>1942</td>\n",
       "      <td>Luwin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Westeros</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Stark</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.351171</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.351171</td>\n",
       "      <td>1</td>\n",
       "      <td>0.351171</td>\n",
       "      <td>1.351171</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>1943</td>\n",
       "      <td>Reek</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Bolton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.096990</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.096990</td>\n",
       "      <td>1</td>\n",
       "      <td>0.096990</td>\n",
       "      <td>1.096990</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>1944</td>\n",
       "      <td>Symeon Star-Eyes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>1945</td>\n",
       "      <td>Coldhands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Three-eyed crow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>1.130435</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>1946</td>\n",
       "      <td>Tytos Lannister</td>\n",
       "      <td>Casterly Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Lannister</td>\n",
       "      <td>Jeyne Marbrand</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.210702</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.210702</td>\n",
       "      <td>1</td>\n",
       "      <td>4.210702</td>\n",
       "      <td>5.210702</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1946 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Order                  name                 title   culture  dateOfBirth              mother            father                heir            house               spouse  book1_A_Game_Of_Thrones  book2_A_Clash_Of_Kings  book3_A_Storm_Of_Swords  book4_A_Feast_For_Crows  book5_A_Dance_with_Dragons  isAliveMother  isAliveFather  isAliveHeir  isAliveSpouse  isMarried  isNoble   age  numDeadRelations  popularity  isAlive  mother_unknown  father_unknown  house_unknown  culture_unknown  title_unknown  heir_unknown  spouse_unknown  age_unknown  isAliveMother_unknown  isAliveFather_unknown  isAliveHeir_unknown  isAliveSpouse_unknown  isAliveParent_unknown  isAliveFamily_unknown  familiarity_mother  familiarity_mother_2  familiarity_father  familiarity_father_2  nobel_real  popularity_survive  heir_survive  heir_survive_2  heir_survive_3  alive_fam  alive_books  alive_books_longest gender_guess  m_gender  is_female\n",
       "0         1  Viserys II Targaryen                   NaN       NaN          NaN  Rhaenyra Targaryen  Daemon Targaryen  Aegon IV Targaryen              NaN                  NaN                        0                       0                        0                        0                           0            1.0            0.0          0.0            NaN          0        0   NaN                11    0.605351        0               0               0              1                1              1             0               1            1                      0                      0                    0                      1                      0                      1                   1                     0                   1                     1           0           11.605351             1       11.605351       12.605351          0            0                    0      unknown         1          0\n",
       "1         2           Walder Frey  Lord of the Crossing  Rivermen        208.0                 NaN               NaN                 NaN       House Frey          Perra Royce                        1                       1                        1                        1                           1            NaN            NaN          NaN            1.0          1        1  97.0                 1    0.896321        1               1               1              0                0              0             1               0            0                      1                      1                    1                      0                      2                      1                   1                     1                   1                     1           1            1.896321             1        1.896321        2.896321          0            5                    1      unknown         1          0\n",
       "2         3          Addison Hill                   Ser       NaN          NaN                 NaN               NaN                 NaN      House Swyft                  NaN                        0                       0                        0                        1                           0            NaN            NaN          NaN            NaN          0        1   NaN                 0    0.267559        1               1               1              0                1              0             1               1            1                      1                      1                    1                      1                      2                      0                   0                     0                   1                     1           1            0.267559             1        0.267559        1.267559          0            1                    0         andy         0          0\n",
       "3         4           Aemma Arryn                 Queen       NaN         82.0                 NaN               NaN                 NaN      House Arryn  Viserys I Targaryen                        0                       0                        0                        0                           0            NaN            NaN          NaN            0.0          1        1  23.0                 0    0.183946        0               1               1              0                1              0             1               0            0                      1                      1                    1                      0                      2                      1                   0                     0                   1                     1           1            0.183946             1        0.183946        1.183946          0            0                    0      unknown         1          0\n",
       "4         5        Sylva Santagar            Greenstone   Dornish        276.0                 NaN               NaN                 NaN   House Santagar      Eldon Estermont                        0                       0                        0                        1                           0            NaN            NaN          NaN            1.0          1        1  29.0                 0    0.043478        1               1               1              0                0              0             1               0            0                      1                      1                    1                      0                      2                      1                   1                     1                   1                     1           1            0.043478             1        0.043478        1.043478          0            1                    0       female         0          1\n",
       "...     ...                   ...                   ...       ...          ...                 ...               ...                 ...              ...                  ...                      ...                     ...                      ...                      ...                         ...            ...            ...          ...            ...        ...      ...   ...               ...         ...      ...             ...             ...            ...              ...            ...           ...             ...          ...                    ...                    ...                  ...                    ...                    ...                    ...                 ...                   ...                 ...                   ...         ...                 ...           ...             ...             ...        ...          ...                  ...          ...       ...        ...\n",
       "1941   1942                 Luwin                   NaN  Westeros          NaN                 NaN               NaN                 NaN      House Stark                  NaN                        1                       1                        1                        1                           1            NaN            NaN          NaN            NaN          0        0   NaN                 0    0.351171        0               1               1              0                0              1             1               1            1                      1                      1                    1                      1                      2                      0                   1                     1                   1                     1           0            0.351171             1        0.351171        1.351171          0            5                    1      unknown         1          0\n",
       "1942   1943                  Reek                   NaN       NaN          NaN                 NaN               NaN                 NaN     House Bolton                  NaN                        0                       1                        0                        1                           1            NaN            NaN          NaN            NaN          0        0   NaN                 0    0.096990        0               1               1              0                1              1             1               1            1                      1                      1                    1                      1                      2                      0                   0                     0                   1                     1           0            0.096990             1        0.096990        1.096990          0            3                    0      unknown         1          0\n",
       "1943   1944      Symeon Star-Eyes                   NaN       NaN          NaN                 NaN               NaN                 NaN              NaN                  NaN                        1                       1                        1                        1                           1            NaN            NaN          NaN            NaN          0        0   NaN                 0    0.030100        1               1               1              1                1              1             1               1            1                      1                      1                    1                      1                      2                      0                   0                     0                   0                     0           0            0.030100             1        0.000000        0.030100          0            5                    1         male         0          0\n",
       "1944   1945             Coldhands                   NaN       NaN          NaN                 NaN               NaN                 NaN  Three-eyed crow                  NaN                        0                       0                        1                        1                           1            NaN            NaN          NaN            NaN          0        0   NaN                 0    0.130435        1               1               1              0                1              1             1               1            1                      1                      1                    1                      1                      2                      0                   0                     0                   1                     1           0            0.130435             1        0.130435        1.130435          0            3                    0      unknown         1          0\n",
       "1945   1946       Tytos Lannister         Casterly Rock       NaN        220.0                 NaN               NaN                 NaN  House Lannister       Jeyne Marbrand                        0                       0                        1                        1                           1            NaN            NaN          NaN            1.0          1        1  47.0                 4    0.210702        0               1               1              0                1              0             1               0            0                      1                      1                    1                      0                      2                      1                   0                     0                   1                     1           1            4.210702             1        4.210702        5.210702          0            3                    0      unknown         1          0\n",
       "\n",
       "[1946 rows x 54 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a copy of the dataset, just in case\n",
    "GOT_data_2= GOT.copy()\n",
    "GOT_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7221b435",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.585716Z",
     "start_time": "2021-12-05T21:32:28.575130Z"
    }
   },
   "outputs": [],
   "source": [
    "GOT_data_2=GOT_data_2.drop(labels='name',axis=1)\n",
    "GOT_data_2=GOT_data_2.drop(labels='title',axis=1)\n",
    "GOT_data_2=GOT_data_2.drop(labels='culture',axis=1)\n",
    "GOT_data_2=GOT_data_2.drop(labels='dateOfBirth',axis=1)\n",
    "GOT_data_2=GOT_data_2.drop(labels='mother',axis=1)\n",
    "GOT_data_2=GOT_data_2.drop(labels='father',axis=1)\n",
    "GOT_data_2=GOT_data_2.drop(labels='heir',axis=1)\n",
    "GOT_data_2=GOT_data_2.drop(labels='house',axis=1)\n",
    "GOT_data_2=GOT_data_2.drop(labels='spouse',axis=1)\n",
    "GOT_data_2=GOT_data_2.drop(labels='isAliveMother',axis=1)\n",
    "GOT_data_2=GOT_data_2.drop(labels='isAliveFather',axis=1)\n",
    "GOT_data_2=GOT_data_2.drop(labels='isAliveSpouse',axis=1)\n",
    "GOT_data_2=GOT_data_2.drop(labels='isAliveHeir',axis=1)\n",
    "GOT_data_2=GOT_data_2.drop(labels='age',axis=1)\n",
    "#drop all the variables that are later not needed for the full dataset\n",
    "#not needed since new features created and these contain the missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a2ad5523",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.589587Z",
     "start_time": "2021-12-05T21:32:28.586604Z"
    }
   },
   "outputs": [],
   "source": [
    "# declaring explanatory variables\n",
    "GOT_data_2=GOT.drop('isAlive', axis=1)\n",
    "\n",
    "\n",
    "# declaring response variable\n",
    "GOT_target= GOT.loc[:,'isAlive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ec81d249",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.596942Z",
     "start_time": "2021-12-05T21:32:28.590462Z"
    }
   },
   "outputs": [],
   "source": [
    "# train-test split with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            GOT_data_2,\n",
    "            GOT_target,\n",
    "            test_size    = 0.10,\n",
    "            random_state = 219,\n",
    "            stratify     = GOT_target) # preserving balance\n",
    "\n",
    "\n",
    "# merging training data for statsmodels\n",
    "GOT_train = pd.concat([x_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6634c554",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.601597Z",
     "start_time": "2021-12-05T21:32:28.597899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Response Variable Proportions (Training Set)\n",
      "--------------------------------------------\n",
      "1    0.75\n",
      "0    0.25\n",
      "Name: isAlive, dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "Response Variable Proportions (Testing Set)\n",
      "--------------------------------------------\n",
      "1    0.74\n",
      "0    0.26\n",
      "Name: isAlive, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "\n",
    "Response Variable Proportions (Training Set)\n",
    "--------------------------------------------\n",
    "{y_train.value_counts(normalize = True).round(decimals = 2)}\n",
    "\n",
    "\n",
    "\n",
    "Response Variable Proportions (Testing Set)\n",
    "--------------------------------------------\n",
    "{y_test.value_counts(normalize = True).round(decimals = 2)}\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f798fc",
   "metadata": {},
   "source": [
    "## Logistic regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "424fd6d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.605001Z",
     "start_time": "2021-12-05T21:32:28.602594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Order + \n",
      " name + \n",
      " title + \n",
      " culture + \n",
      " dateOfBirth + \n",
      " mother + \n",
      " father + \n",
      " heir + \n",
      " house + \n",
      " spouse + \n",
      " book1_A_Game_Of_Thrones + \n",
      " book2_A_Clash_Of_Kings + \n",
      " book3_A_Storm_Of_Swords + \n",
      " book4_A_Feast_For_Crows + \n",
      " book5_A_Dance_with_Dragons + \n",
      " isAliveMother + \n",
      " isAliveFather + \n",
      " isAliveHeir + \n",
      " isAliveSpouse + \n",
      " isMarried + \n",
      " isNoble + \n",
      " age + \n",
      " numDeadRelations + \n",
      " popularity + \n",
      " mother_unknown + \n",
      " father_unknown + \n",
      " house_unknown + \n",
      " culture_unknown + \n",
      " title_unknown + \n",
      " heir_unknown + \n",
      " spouse_unknown + \n",
      " age_unknown + \n",
      " isAliveMother_unknown + \n",
      " isAliveFather_unknown + \n",
      " isAliveHeir_unknown + \n",
      " isAliveSpouse_unknown + \n",
      " isAliveParent_unknown + \n",
      " isAliveFamily_unknown + \n",
      " familiarity_mother + \n",
      " familiarity_mother_2 + \n",
      " familiarity_father + \n",
      " familiarity_father_2 + \n",
      " nobel_real + \n",
      " popularity_survive + \n",
      " heir_survive + \n",
      " heir_survive_2 + \n",
      " heir_survive_3 + \n",
      " alive_fam + \n",
      " alive_books + \n",
      " alive_books_longest + \n",
      " gender_guess + \n",
      " m_gender + \n",
      " is_female + \n"
     ]
    }
   ],
   "source": [
    "#print out all th variables with a plus so thay can asier be inputted into the logistic regressions\n",
    "for val in GOT_data_2:\n",
    "    print(f\" {val} + \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cb9dcb",
   "metadata": {},
   "source": [
    "### Logit_full 0.478693\n",
    "Regression with all* the variables\n",
    "\n",
    "\n",
    "\n",
    "*doesn't include all since otherwise error would occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b679e979",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.670918Z",
     "start_time": "2021-12-05T21:32:28.606001Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.478693\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.156</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>      <td>isAlive</td>           <td>AIC:</td>         <td>1718.3836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-12-05 16:32</td>       <td>BIC:</td>         <td>1833.2104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>1751</td>        <td>Log-Likelihood:</td>    <td>-838.19</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>20</td>            <td>LL-Null:</td>        <td>-992.53</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>1730</td>         <td>LLR p-value:</td>    <td>1.3569e-53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>              <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>-2.0521</td>  <td>1.0300</td>  <td>-1.9923</td> <td>0.0463</td> <td>-4.0710</td> <td>-0.0333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Order</th>                   <td>-0.0007</td>  <td>0.0001</td>  <td>-5.1190</td> <td>0.0000</td> <td>-0.0009</td> <td>-0.0004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book1_A_Game_Of_Thrones</th> <td>-0.8696</td>  <td>0.2384</td>  <td>-3.6479</td> <td>0.0003</td> <td>-1.3368</td> <td>-0.4024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book2_A_Clash_Of_Kings</th>  <td>-0.3019</td>  <td>0.2101</td>  <td>-1.4366</td> <td>0.1508</td> <td>-0.7138</td> <td>0.1100</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book3_A_Storm_Of_Swords</th> <td>-0.2542</td>  <td>0.2171</td>  <td>-1.1711</td> <td>0.2416</td> <td>-0.6796</td> <td>0.1712</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book4_A_Feast_For_Crows</th> <td>1.7434</td>   <td>0.2496</td>  <td>6.9840</td>  <td>0.0000</td> <td>1.2541</td>  <td>2.2326</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>culture_unknown</th>         <td>0.0301</td>   <td>0.1369</td>  <td>0.2200</td>  <td>0.8259</td> <td>-0.2382</td> <td>0.2985</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isNoble</th>                 <td>-0.1505</td>  <td>0.4740</td>  <td>-0.3175</td> <td>0.7509</td> <td>-1.0795</td> <td>0.7786</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numDeadRelations</th>        <td>-0.1017</td>  <td>0.0509</td>  <td>-1.9981</td> <td>0.0457</td> <td>-0.2015</td> <td>-0.0019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>popularity</th>              <td>-0.3551</td>  <td>0.5375</td>  <td>-0.6605</td> <td>0.5089</td> <td>-1.4086</td> <td>0.6985</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_unknown</th>          <td>1.8167</td>   <td>1.2331</td>  <td>1.4733</td>  <td>0.1407</td> <td>-0.6001</td> <td>4.2334</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>father_unknown</th>          <td>-0.0320</td>  <td>1.0529</td>  <td>-0.0304</td> <td>0.9757</td> <td>-2.0957</td> <td>2.0316</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>house_unknown</th>           <td>0.2397</td>   <td>0.1686</td>  <td>1.4210</td>  <td>0.1553</td> <td>-0.0909</td> <td>0.5702</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_unknown</th>           <td>-0.0804</td>  <td>0.4707</td>  <td>-0.1708</td> <td>0.8644</td> <td>-1.0030</td> <td>0.8422</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>heir_unknown</th>            <td>0.7084</td>   <td>0.9115</td>  <td>0.7772</td>  <td>0.4370</td> <td>-1.0780</td> <td>2.4949</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spouse_unknown</th>          <td>0.1225</td>   <td>0.1878</td>  <td>0.6521</td>  <td>0.5144</td> <td>-0.2457</td> <td>0.4906</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_unknown</th>             <td>0.8156</td>   <td>0.1585</td>  <td>5.1444</td>  <td>0.0000</td> <td>0.5049</td>  <td>1.1263</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_gender</th>                <td>0.1560</td>   <td>0.1535</td>  <td>1.0167</td>  <td>0.3093</td> <td>-0.1448</td> <td>0.4568</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_female</th>               <td>0.4862</td>   <td>0.2813</td>  <td>1.7283</td>  <td>0.0839</td> <td>-0.0652</td> <td>1.0376</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alive_books</th>             <td>0.0062</td>   <td>0.1566</td>  <td>0.0398</td>  <td>0.9682</td> <td>-0.3007</td> <td>0.3132</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alive_books_longest</th>     <td>0.9934</td>   <td>0.3116</td>  <td>3.1882</td>  <td>0.0014</td> <td>0.3827</td>  <td>1.6042</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                            Results: Logit\n",
       "=======================================================================\n",
       "Model:                Logit              Pseudo R-squared:   0.156     \n",
       "Dependent Variable:   isAlive            AIC:                1718.3836 \n",
       "Date:                 2021-12-05 16:32   BIC:                1833.2104 \n",
       "No. Observations:     1751               Log-Likelihood:     -838.19   \n",
       "Df Model:             20                 LL-Null:            -992.53   \n",
       "Df Residuals:         1730               LLR p-value:        1.3569e-53\n",
       "Converged:            1.0000             Scale:              1.0000    \n",
       "No. Iterations:       6.0000                                           \n",
       "-----------------------------------------------------------------------\n",
       "                         Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
       "-----------------------------------------------------------------------\n",
       "Intercept               -2.0521   1.0300 -1.9923 0.0463 -4.0710 -0.0333\n",
       "Order                   -0.0007   0.0001 -5.1190 0.0000 -0.0009 -0.0004\n",
       "book1_A_Game_Of_Thrones -0.8696   0.2384 -3.6479 0.0003 -1.3368 -0.4024\n",
       "book2_A_Clash_Of_Kings  -0.3019   0.2101 -1.4366 0.1508 -0.7138  0.1100\n",
       "book3_A_Storm_Of_Swords -0.2542   0.2171 -1.1711 0.2416 -0.6796  0.1712\n",
       "book4_A_Feast_For_Crows  1.7434   0.2496  6.9840 0.0000  1.2541  2.2326\n",
       "culture_unknown          0.0301   0.1369  0.2200 0.8259 -0.2382  0.2985\n",
       "isNoble                 -0.1505   0.4740 -0.3175 0.7509 -1.0795  0.7786\n",
       "numDeadRelations        -0.1017   0.0509 -1.9981 0.0457 -0.2015 -0.0019\n",
       "popularity              -0.3551   0.5375 -0.6605 0.5089 -1.4086  0.6985\n",
       "mother_unknown           1.8167   1.2331  1.4733 0.1407 -0.6001  4.2334\n",
       "father_unknown          -0.0320   1.0529 -0.0304 0.9757 -2.0957  2.0316\n",
       "house_unknown            0.2397   0.1686  1.4210 0.1553 -0.0909  0.5702\n",
       "title_unknown           -0.0804   0.4707 -0.1708 0.8644 -1.0030  0.8422\n",
       "heir_unknown             0.7084   0.9115  0.7772 0.4370 -1.0780  2.4949\n",
       "spouse_unknown           0.1225   0.1878  0.6521 0.5144 -0.2457  0.4906\n",
       "age_unknown              0.8156   0.1585  5.1444 0.0000  0.5049  1.1263\n",
       "m_gender                 0.1560   0.1535  1.0167 0.3093 -0.1448  0.4568\n",
       "is_female                0.4862   0.2813  1.7283 0.0839 -0.0652  1.0376\n",
       "alive_books              0.0062   0.1566  0.0398 0.9682 -0.3007  0.3132\n",
       "alive_books_longest      0.9934   0.3116  3.1882 0.0014  0.3827  1.6042\n",
       "=======================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_small = smf.logit(formula   = \"\"\"isAlive~ \n",
    "Order +  \n",
    " book1_A_Game_Of_Thrones + \n",
    " book2_A_Clash_Of_Kings + \n",
    " book3_A_Storm_Of_Swords + \n",
    " book4_A_Feast_For_Crows + \n",
    " culture_unknown + \n",
    " isNoble + \n",
    " numDeadRelations + \n",
    " popularity +\n",
    " mother_unknown + \n",
    " father_unknown + \n",
    " house_unknown + \n",
    " title_unknown + \n",
    " heir_unknown + \n",
    " spouse_unknown + \n",
    " age_unknown +\n",
    "m_gender+ \n",
    " is_female+\n",
    "  alive_books + \n",
    " alive_books_longest  \n",
    " \"\"\",\n",
    "                           data = GOT_train)\n",
    " \n",
    "\n",
    "# FITTING the model object\n",
    "results_logistic = logistic_small.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary2() # summary2() has AIC and BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b515b67",
   "metadata": {},
   "source": [
    "### Logit 5 0.490102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "71bb5bb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.709508Z",
     "start_time": "2021-12-05T21:32:28.672450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.490102\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.135</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>      <td>isAlive</td>           <td>AIC:</td>         <td>1732.3366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-12-05 16:32</td>       <td>BIC:</td>         <td>1776.0801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>1751</td>        <td>Log-Likelihood:</td>    <td>-858.17</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>7</td>            <td>LL-Null:</td>        <td>-992.53</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>1743</td>         <td>LLR p-value:</td>    <td>2.8375e-54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>              <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>1.3979</td>   <td>0.1286</td>  <td>10.8739</td> <td>0.0000</td> <td>1.1459</td>  <td>1.6498</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Order</th>                   <td>-0.0007</td>  <td>0.0001</td>  <td>-6.1358</td> <td>0.0000</td> <td>-0.0010</td> <td>-0.0005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book1_A_Game_Of_Thrones</th> <td>-0.7259</td>  <td>0.1895</td>  <td>-3.8314</td> <td>0.0001</td> <td>-1.0972</td> <td>-0.3546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book2_A_Clash_Of_Kings</th>  <td>-0.3919</td>  <td>0.1374</td>  <td>-2.8529</td> <td>0.0043</td> <td>-0.6611</td> <td>-0.1227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book4_A_Feast_For_Crows</th> <td>1.5795</td>   <td>0.1408</td>  <td>11.2183</td> <td>0.0000</td> <td>1.3036</td>  <td>1.8555</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numDeadRelations</th>        <td>-0.1618</td>  <td>0.0508</td>  <td>-3.1847</td> <td>0.0014</td> <td>-0.2613</td> <td>-0.0622</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>popularity</th>              <td>-1.4702</td>  <td>0.4600</td>  <td>-3.1959</td> <td>0.0014</td> <td>-2.3718</td> <td>-0.5685</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alive_books_longest</th>     <td>0.9715</td>   <td>0.2933</td>  <td>3.3127</td>  <td>0.0009</td> <td>0.3967</td>  <td>1.5463</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                            Results: Logit\n",
       "=======================================================================\n",
       "Model:                Logit              Pseudo R-squared:   0.135     \n",
       "Dependent Variable:   isAlive            AIC:                1732.3366 \n",
       "Date:                 2021-12-05 16:32   BIC:                1776.0801 \n",
       "No. Observations:     1751               Log-Likelihood:     -858.17   \n",
       "Df Model:             7                  LL-Null:            -992.53   \n",
       "Df Residuals:         1743               LLR p-value:        2.8375e-54\n",
       "Converged:            1.0000             Scale:              1.0000    \n",
       "No. Iterations:       6.0000                                           \n",
       "-----------------------------------------------------------------------\n",
       "                         Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
       "-----------------------------------------------------------------------\n",
       "Intercept                1.3979   0.1286 10.8739 0.0000  1.1459  1.6498\n",
       "Order                   -0.0007   0.0001 -6.1358 0.0000 -0.0010 -0.0005\n",
       "book1_A_Game_Of_Thrones -0.7259   0.1895 -3.8314 0.0001 -1.0972 -0.3546\n",
       "book2_A_Clash_Of_Kings  -0.3919   0.1374 -2.8529 0.0043 -0.6611 -0.1227\n",
       "book4_A_Feast_For_Crows  1.5795   0.1408 11.2183 0.0000  1.3036  1.8555\n",
       "numDeadRelations        -0.1618   0.0508 -3.1847 0.0014 -0.2613 -0.0622\n",
       "popularity              -1.4702   0.4600 -3.1959 0.0014 -2.3718 -0.5685\n",
       "alive_books_longest      0.9715   0.2933  3.3127 0.0009  0.3967  1.5463\n",
       "=======================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_small = smf.logit(formula   = \"\"\"isAlive~ \n",
    "Order + \n",
    " book1_A_Game_Of_Thrones + \n",
    " book2_A_Clash_Of_Kings + \n",
    "\n",
    " book4_A_Feast_For_Crows + \n",
    "\n",
    " numDeadRelations + \n",
    " popularity+\n",
    " alive_books_longest\n",
    " \n",
    "\n",
    " \"\"\",\n",
    "                           data = GOT_train)\n",
    " \n",
    "\n",
    "# FITTING the model object\n",
    "results_logistic = logistic_small.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary2() # summary2() has AIC and BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e236fa02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:04:34.209660Z",
     "start_time": "2021-12-04T18:04:34.204705Z"
    }
   },
   "source": [
    "### logit_full_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "df7cd13e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.743270Z",
     "start_time": "2021-12-05T21:32:28.710930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.487631\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.140</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>      <td>isAlive</td>           <td>AIC:</td>         <td>1719.6847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-12-05 16:32</td>       <td>BIC:</td>         <td>1752.4924</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>1751</td>        <td>Log-Likelihood:</td>    <td>-853.84</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>5</td>            <td>LL-Null:</td>        <td>-992.53</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>1745</td>         <td>LLR p-value:</td>    <td>7.2629e-58</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>              <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>-2.3518</td>  <td>0.6487</td>  <td>-3.6251</td> <td>0.0003</td> <td>-3.6233</td> <td>-1.0802</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Order</th>                   <td>-0.0008</td>  <td>0.0001</td>  <td>-6.5398</td> <td>0.0000</td> <td>-0.0010</td> <td>-0.0005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book1_A_Game_Of_Thrones</th> <td>-0.6352</td>  <td>0.1449</td>  <td>-4.3843</td> <td>0.0000</td> <td>-0.9192</td> <td>-0.3512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book4_A_Feast_For_Crows</th> <td>1.7227</td>   <td>0.1382</td>  <td>12.4634</td> <td>0.0000</td> <td>1.4518</td>  <td>1.9936</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_unknown</th>          <td>2.7961</td>   <td>0.6387</td>  <td>4.3779</td>  <td>0.0000</td> <td>1.5443</td>  <td>4.0479</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_unknown</th>             <td>0.9275</td>   <td>0.1422</td>  <td>6.5246</td>  <td>0.0000</td> <td>0.6489</td>  <td>1.2062</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                            Results: Logit\n",
       "=======================================================================\n",
       "Model:                Logit              Pseudo R-squared:   0.140     \n",
       "Dependent Variable:   isAlive            AIC:                1719.6847 \n",
       "Date:                 2021-12-05 16:32   BIC:                1752.4924 \n",
       "No. Observations:     1751               Log-Likelihood:     -853.84   \n",
       "Df Model:             5                  LL-Null:            -992.53   \n",
       "Df Residuals:         1745               LLR p-value:        7.2629e-58\n",
       "Converged:            1.0000             Scale:              1.0000    \n",
       "No. Iterations:       6.0000                                           \n",
       "-----------------------------------------------------------------------\n",
       "                         Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
       "-----------------------------------------------------------------------\n",
       "Intercept               -2.3518   0.6487 -3.6251 0.0003 -3.6233 -1.0802\n",
       "Order                   -0.0008   0.0001 -6.5398 0.0000 -0.0010 -0.0005\n",
       "book1_A_Game_Of_Thrones -0.6352   0.1449 -4.3843 0.0000 -0.9192 -0.3512\n",
       "book4_A_Feast_For_Crows  1.7227   0.1382 12.4634 0.0000  1.4518  1.9936\n",
       "mother_unknown           2.7961   0.6387  4.3779 0.0000  1.5443  4.0479\n",
       "age_unknown              0.9275   0.1422  6.5246 0.0000  0.6489  1.2062\n",
       "=======================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_small = smf.logit(formula   = \"\"\"isAlive~ \n",
    "Order +  \n",
    " book1_A_Game_Of_Thrones + \n",
    " book4_A_Feast_For_Crows + \n",
    " mother_unknown + \n",
    " age_unknown \n",
    "  \n",
    "\n",
    " \"\"\",\n",
    "                           data = GOT_train)\n",
    " \n",
    "\n",
    "# FITTING the model object\n",
    "results_logistic = logistic_small.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary2() # summary2() has AIC and BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ebf99",
   "metadata": {},
   "source": [
    "### Log_sig 2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "51545307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.782039Z",
     "start_time": "2021-12-05T21:32:28.744784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.484654\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.145</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>      <td>isAlive</td>           <td>AIC:</td>         <td>1713.2585</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-12-05 16:32</td>       <td>BIC:</td>         <td>1757.0020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>1751</td>        <td>Log-Likelihood:</td>    <td>-848.63</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>7</td>            <td>LL-Null:</td>        <td>-992.53</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>1743</td>         <td>LLR p-value:</td>    <td>2.4217e-58</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>              <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>-1.6381</td>  <td>0.7008</td>  <td>-2.3376</td> <td>0.0194</td> <td>-3.0116</td> <td>-0.2646</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Order</th>                   <td>-0.0007</td>  <td>0.0001</td>  <td>-6.1780</td> <td>0.0000</td> <td>-0.0010</td> <td>-0.0005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book1_A_Game_Of_Thrones</th> <td>-0.4717</td>  <td>0.1553</td>  <td>-3.0375</td> <td>0.0024</td> <td>-0.7761</td> <td>-0.1673</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book2_A_Clash_Of_Kings</th>  <td>-0.2724</td>  <td>0.1374</td>  <td>-1.9827</td> <td>0.0474</td> <td>-0.5417</td> <td>-0.0031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book4_A_Feast_For_Crows</th> <td>1.7668</td>   <td>0.1416</td>  <td>12.4760</td> <td>0.0000</td> <td>1.4892</td>  <td>2.0444</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numDeadRelations</th>        <td>-0.1114</td>  <td>0.0437</td>  <td>-2.5503</td> <td>0.0108</td> <td>-0.1970</td> <td>-0.0258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_unknown</th>          <td>2.2374</td>   <td>0.6790</td>  <td>3.2953</td>  <td>0.0010</td> <td>0.9066</td>  <td>3.5681</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_unknown</th>             <td>0.7891</td>   <td>0.1498</td>  <td>5.2693</td>  <td>0.0000</td> <td>0.4956</td>  <td>1.0826</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                            Results: Logit\n",
       "=======================================================================\n",
       "Model:                Logit              Pseudo R-squared:   0.145     \n",
       "Dependent Variable:   isAlive            AIC:                1713.2585 \n",
       "Date:                 2021-12-05 16:32   BIC:                1757.0020 \n",
       "No. Observations:     1751               Log-Likelihood:     -848.63   \n",
       "Df Model:             7                  LL-Null:            -992.53   \n",
       "Df Residuals:         1743               LLR p-value:        2.4217e-58\n",
       "Converged:            1.0000             Scale:              1.0000    \n",
       "No. Iterations:       6.0000                                           \n",
       "-----------------------------------------------------------------------\n",
       "                         Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
       "-----------------------------------------------------------------------\n",
       "Intercept               -1.6381   0.7008 -2.3376 0.0194 -3.0116 -0.2646\n",
       "Order                   -0.0007   0.0001 -6.1780 0.0000 -0.0010 -0.0005\n",
       "book1_A_Game_Of_Thrones -0.4717   0.1553 -3.0375 0.0024 -0.7761 -0.1673\n",
       "book2_A_Clash_Of_Kings  -0.2724   0.1374 -1.9827 0.0474 -0.5417 -0.0031\n",
       "book4_A_Feast_For_Crows  1.7668   0.1416 12.4760 0.0000  1.4892  2.0444\n",
       "numDeadRelations        -0.1114   0.0437 -2.5503 0.0108 -0.1970 -0.0258\n",
       "mother_unknown           2.2374   0.6790  3.2953 0.0010  0.9066  3.5681\n",
       "age_unknown              0.7891   0.1498  5.2693 0.0000  0.4956  1.0826\n",
       "=======================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_small = smf.logit(formula   = \"\"\"isAlive~ \n",
    "Order +  \n",
    " book1_A_Game_Of_Thrones + \n",
    " book2_A_Clash_Of_Kings + \n",
    " book4_A_Feast_For_Crows +  \n",
    " numDeadRelations + \n",
    " mother_unknown + \n",
    " age_unknown\n",
    "\n",
    " \"\"\",\n",
    "                           data = GOT_train)\n",
    " \n",
    "\n",
    "# FITTING the model object\n",
    "results_logistic = logistic_small.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary2() # summary2() has AIC and BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dd9d64",
   "metadata": {},
   "source": [
    "### Logit_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "edd42df7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.812764Z",
     "start_time": "2021-12-05T21:32:28.783574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.506736\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.106</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>      <td>isAlive</td>           <td>AIC:</td>         <td>1786.5886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-12-05 16:32</td>       <td>BIC:</td>         <td>1819.3963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>1751</td>        <td>Log-Likelihood:</td>    <td>-887.29</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>5</td>            <td>LL-Null:</td>        <td>-992.53</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>1745</td>         <td>LLR p-value:</td>    <td>1.6248e-43</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>              <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>-2.9402</td>  <td>0.5187</td>  <td>-5.6684</td> <td>0.0000</td> <td>-3.9569</td> <td>-1.9236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book4_A_Feast_For_Crows</th> <td>1.4107</td>   <td>0.1254</td>  <td>11.2504</td> <td>0.0000</td> <td>1.1650</td>  <td>1.6565</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_unknown</th>             <td>1.0799</td>   <td>0.1394</td>  <td>7.7469</td>  <td>0.0000</td> <td>0.8067</td>  <td>1.3531</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>father_unknown</th>          <td>2.2866</td>   <td>0.4912</td>  <td>4.6553</td>  <td>0.0000</td> <td>1.3239</td>  <td>3.2494</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>house_unknown</th>           <td>0.4555</td>   <td>0.1567</td>  <td>2.9075</td>  <td>0.0036</td> <td>0.1485</td>  <td>0.7626</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_unknown</th>           <td>0.2521</td>   <td>0.1195</td>  <td>2.1094</td>  <td>0.0349</td> <td>0.0179</td>  <td>0.4864</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                            Results: Logit\n",
       "=======================================================================\n",
       "Model:                Logit              Pseudo R-squared:   0.106     \n",
       "Dependent Variable:   isAlive            AIC:                1786.5886 \n",
       "Date:                 2021-12-05 16:32   BIC:                1819.3963 \n",
       "No. Observations:     1751               Log-Likelihood:     -887.29   \n",
       "Df Model:             5                  LL-Null:            -992.53   \n",
       "Df Residuals:         1745               LLR p-value:        1.6248e-43\n",
       "Converged:            1.0000             Scale:              1.0000    \n",
       "No. Iterations:       6.0000                                           \n",
       "-----------------------------------------------------------------------\n",
       "                         Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
       "-----------------------------------------------------------------------\n",
       "Intercept               -2.9402   0.5187 -5.6684 0.0000 -3.9569 -1.9236\n",
       "book4_A_Feast_For_Crows  1.4107   0.1254 11.2504 0.0000  1.1650  1.6565\n",
       "age_unknown              1.0799   0.1394  7.7469 0.0000  0.8067  1.3531\n",
       "father_unknown           2.2866   0.4912  4.6553 0.0000  1.3239  3.2494\n",
       "house_unknown            0.4555   0.1567  2.9075 0.0036  0.1485  0.7626\n",
       "title_unknown            0.2521   0.1195  2.1094 0.0349  0.0179  0.4864\n",
       "=======================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_small = smf.logit(formula   = \"\"\"isAlive~ book4_A_Feast_For_Crows\n",
    "+age_unknown \n",
    " \n",
    "+father_unknown\n",
    " \n",
    "       \n",
    "+house_unknown                 \n",
    "             \n",
    "+title_unknown\n",
    "\n",
    " \"\"\",\n",
    "                           data = GOT_train)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "results_logistic = logistic_small.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary2() # summary2() has AIC and BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb77e3",
   "metadata": {},
   "source": [
    "## Logit_Sig, 0.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "991f0e65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.847947Z",
     "start_time": "2021-12-05T21:32:28.814103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.484654\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.145</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>      <td>isAlive</td>           <td>AIC:</td>         <td>1713.2585</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-12-05 16:32</td>       <td>BIC:</td>         <td>1757.0020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>1751</td>        <td>Log-Likelihood:</td>    <td>-848.63</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>7</td>            <td>LL-Null:</td>        <td>-992.53</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>1743</td>         <td>LLR p-value:</td>    <td>2.4217e-58</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>              <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>-1.6381</td>  <td>0.7008</td>  <td>-2.3376</td> <td>0.0194</td> <td>-3.0116</td> <td>-0.2646</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Order</th>                   <td>-0.0007</td>  <td>0.0001</td>  <td>-6.1780</td> <td>0.0000</td> <td>-0.0010</td> <td>-0.0005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book1_A_Game_Of_Thrones</th> <td>-0.4717</td>  <td>0.1553</td>  <td>-3.0375</td> <td>0.0024</td> <td>-0.7761</td> <td>-0.1673</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book2_A_Clash_Of_Kings</th>  <td>-0.2724</td>  <td>0.1374</td>  <td>-1.9827</td> <td>0.0474</td> <td>-0.5417</td> <td>-0.0031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book4_A_Feast_For_Crows</th> <td>1.7668</td>   <td>0.1416</td>  <td>12.4760</td> <td>0.0000</td> <td>1.4892</td>  <td>2.0444</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numDeadRelations</th>        <td>-0.1114</td>  <td>0.0437</td>  <td>-2.5503</td> <td>0.0108</td> <td>-0.1970</td> <td>-0.0258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_unknown</th>          <td>2.2374</td>   <td>0.6790</td>  <td>3.2953</td>  <td>0.0010</td> <td>0.9066</td>  <td>3.5681</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_unknown</th>             <td>0.7891</td>   <td>0.1498</td>  <td>5.2693</td>  <td>0.0000</td> <td>0.4956</td>  <td>1.0826</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                            Results: Logit\n",
       "=======================================================================\n",
       "Model:                Logit              Pseudo R-squared:   0.145     \n",
       "Dependent Variable:   isAlive            AIC:                1713.2585 \n",
       "Date:                 2021-12-05 16:32   BIC:                1757.0020 \n",
       "No. Observations:     1751               Log-Likelihood:     -848.63   \n",
       "Df Model:             7                  LL-Null:            -992.53   \n",
       "Df Residuals:         1743               LLR p-value:        2.4217e-58\n",
       "Converged:            1.0000             Scale:              1.0000    \n",
       "No. Iterations:       6.0000                                           \n",
       "-----------------------------------------------------------------------\n",
       "                         Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
       "-----------------------------------------------------------------------\n",
       "Intercept               -1.6381   0.7008 -2.3376 0.0194 -3.0116 -0.2646\n",
       "Order                   -0.0007   0.0001 -6.1780 0.0000 -0.0010 -0.0005\n",
       "book1_A_Game_Of_Thrones -0.4717   0.1553 -3.0375 0.0024 -0.7761 -0.1673\n",
       "book2_A_Clash_Of_Kings  -0.2724   0.1374 -1.9827 0.0474 -0.5417 -0.0031\n",
       "book4_A_Feast_For_Crows  1.7668   0.1416 12.4760 0.0000  1.4892  2.0444\n",
       "numDeadRelations        -0.1114   0.0437 -2.5503 0.0108 -0.1970 -0.0258\n",
       "mother_unknown           2.2374   0.6790  3.2953 0.0010  0.9066  3.5681\n",
       "age_unknown              0.7891   0.1498  5.2693 0.0000  0.4956  1.0826\n",
       "=======================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logit_sig\n",
    "# instantiating a logistic regression model object\n",
    "logistic_small = smf.logit(formula   = \"\"\"isAlive~ \n",
    "Order +  \n",
    " book1_A_Game_Of_Thrones + \n",
    " book2_A_Clash_Of_Kings + \n",
    "\n",
    " book4_A_Feast_For_Crows + \n",
    " \n",
    " numDeadRelations + \n",
    "\n",
    " mother_unknown + \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    " age_unknown\n",
    " \n",
    "\n",
    "\n",
    "             \n",
    " \"\"\",\n",
    "                           data = GOT_train)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "results_logistic = logistic_small.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary2() # summary2() has AIC and BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ec88ca",
   "metadata": {},
   "source": [
    "## Logit_unsig_3 0.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f5ab718e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.885167Z",
     "start_time": "2021-12-05T21:32:28.849301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.483721\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.147</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>      <td>isAlive</td>           <td>AIC:</td>         <td>1711.9908</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-12-05 16:32</td>       <td>BIC:</td>         <td>1761.2023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>1751</td>        <td>Log-Likelihood:</td>    <td>-847.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>8</td>            <td>LL-Null:</td>        <td>-992.53</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>1742</td>         <td>LLR p-value:</td>    <td>3.2595e-58</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>              <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>-1.3359</td>  <td>0.7204</td>  <td>-1.8545</td> <td>0.0637</td> <td>-2.7478</td> <td>0.0760</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Order</th>                   <td>-0.0007</td>  <td>0.0001</td>  <td>-5.8323</td> <td>0.0000</td> <td>-0.0009</td> <td>-0.0005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book1_A_Game_Of_Thrones</th> <td>-0.4713</td>  <td>0.1553</td>  <td>-3.0338</td> <td>0.0024</td> <td>-0.7758</td> <td>-0.1668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book2_A_Clash_Of_Kings</th>  <td>-0.2602</td>  <td>0.1378</td>  <td>-1.8884</td> <td>0.0590</td> <td>-0.5302</td> <td>0.0099</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book4_A_Feast_For_Crows</th> <td>1.7806</td>   <td>0.1420</td>  <td>12.5359</td> <td>0.0000</td> <td>1.5022</td>  <td>2.0590</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numDeadRelations</th>        <td>-0.1112</td>  <td>0.0436</td>  <td>-2.5497</td> <td>0.0108</td> <td>-0.1967</td> <td>-0.0257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_unknown</th>          <td>2.1421</td>   <td>0.6805</td>  <td>3.1480</td>  <td>0.0016</td> <td>0.8084</td>  <td>3.4758</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>familiarity_father_2</th>    <td>-0.2907</td>  <td>0.1627</td>  <td>-1.7866</td> <td>0.0740</td> <td>-0.6095</td> <td>0.0282</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_unknown</th>             <td>0.7648</td>   <td>0.1502</td>  <td>5.0932</td>  <td>0.0000</td> <td>0.4705</td>  <td>1.0591</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                            Results: Logit\n",
       "=======================================================================\n",
       "Model:                Logit              Pseudo R-squared:   0.147     \n",
       "Dependent Variable:   isAlive            AIC:                1711.9908 \n",
       "Date:                 2021-12-05 16:32   BIC:                1761.2023 \n",
       "No. Observations:     1751               Log-Likelihood:     -847.00   \n",
       "Df Model:             8                  LL-Null:            -992.53   \n",
       "Df Residuals:         1742               LLR p-value:        3.2595e-58\n",
       "Converged:            1.0000             Scale:              1.0000    \n",
       "No. Iterations:       6.0000                                           \n",
       "-----------------------------------------------------------------------\n",
       "                         Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
       "-----------------------------------------------------------------------\n",
       "Intercept               -1.3359   0.7204 -1.8545 0.0637 -2.7478  0.0760\n",
       "Order                   -0.0007   0.0001 -5.8323 0.0000 -0.0009 -0.0005\n",
       "book1_A_Game_Of_Thrones -0.4713   0.1553 -3.0338 0.0024 -0.7758 -0.1668\n",
       "book2_A_Clash_Of_Kings  -0.2602   0.1378 -1.8884 0.0590 -0.5302  0.0099\n",
       "book4_A_Feast_For_Crows  1.7806   0.1420 12.5359 0.0000  1.5022  2.0590\n",
       "numDeadRelations        -0.1112   0.0436 -2.5497 0.0108 -0.1967 -0.0257\n",
       "mother_unknown           2.1421   0.6805  3.1480 0.0016  0.8084  3.4758\n",
       "familiarity_father_2    -0.2907   0.1627 -1.7866 0.0740 -0.6095  0.0282\n",
       "age_unknown              0.7648   0.1502  5.0932 0.0000  0.4705  1.0591\n",
       "=======================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'logit_unsig_3'\n",
    "# instantiating a logistic regression model object\n",
    "logistic_small = smf.logit(formula   = \"\"\"isAlive~ \n",
    "Order +  \n",
    " book1_A_Game_Of_Thrones + \n",
    " book2_A_Clash_Of_Kings + \n",
    " book4_A_Feast_For_Crows + \n",
    " numDeadRelations + \n",
    " mother_unknown + \n",
    " familiarity_father_2+ \n",
    "\n",
    "\n",
    "\n",
    "age_unknown   \n",
    "\n",
    " \"\"\",\n",
    "                           data = GOT_train)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "results_logistic = logistic_small.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary2() # summary2() has AIC and BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25bda7a",
   "metadata": {},
   "source": [
    "## Logit_sig 2 0.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d75815ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.920892Z",
     "start_time": "2021-12-05T21:32:28.886950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.484631\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.145</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>      <td>isAlive</td>           <td>AIC:</td>         <td>1713.1782</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-12-05 16:32</td>       <td>BIC:</td>         <td>1756.9217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>1751</td>        <td>Log-Likelihood:</td>    <td>-848.59</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>7</td>            <td>LL-Null:</td>        <td>-992.53</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>1743</td>         <td>LLR p-value:</td>    <td>2.3280e-58</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>              <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>-1.5757</td>  <td>0.7092</td>  <td>-2.2217</td> <td>0.0263</td> <td>-2.9658</td> <td>-0.1857</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book1_A_Game_Of_Thrones</th> <td>-0.4649</td>  <td>0.1558</td>  <td>-2.9839</td> <td>0.0028</td> <td>-0.7703</td> <td>-0.1595</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book2_A_Clash_Of_Kings</th>  <td>-0.2697</td>  <td>0.1374</td>  <td>-1.9632</td> <td>0.0496</td> <td>-0.5390</td> <td>-0.0004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book4_A_Feast_For_Crows</th> <td>1.7689</td>   <td>0.1416</td>  <td>12.4915</td> <td>0.0000</td> <td>1.4914</td>  <td>2.0465</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_unknown</th>          <td>2.1798</td>   <td>0.6858</td>  <td>3.1786</td>  <td>0.0015</td> <td>0.8357</td>  <td>3.5239</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_unknown</th>             <td>0.7815</td>   <td>0.1505</td>  <td>5.1918</td>  <td>0.0000</td> <td>0.4865</td>  <td>1.0766</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>popularity_survive</th>      <td>-0.1067</td>  <td>0.0416</td>  <td>-2.5655</td> <td>0.0103</td> <td>-0.1881</td> <td>-0.0252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Order</th>                   <td>-0.0007</td>  <td>0.0001</td>  <td>-6.1332</td> <td>0.0000</td> <td>-0.0010</td> <td>-0.0005</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                            Results: Logit\n",
       "=======================================================================\n",
       "Model:                Logit              Pseudo R-squared:   0.145     \n",
       "Dependent Variable:   isAlive            AIC:                1713.1782 \n",
       "Date:                 2021-12-05 16:32   BIC:                1756.9217 \n",
       "No. Observations:     1751               Log-Likelihood:     -848.59   \n",
       "Df Model:             7                  LL-Null:            -992.53   \n",
       "Df Residuals:         1743               LLR p-value:        2.3280e-58\n",
       "Converged:            1.0000             Scale:              1.0000    \n",
       "No. Iterations:       6.0000                                           \n",
       "-----------------------------------------------------------------------\n",
       "                         Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
       "-----------------------------------------------------------------------\n",
       "Intercept               -1.5757   0.7092 -2.2217 0.0263 -2.9658 -0.1857\n",
       "book1_A_Game_Of_Thrones -0.4649   0.1558 -2.9839 0.0028 -0.7703 -0.1595\n",
       "book2_A_Clash_Of_Kings  -0.2697   0.1374 -1.9632 0.0496 -0.5390 -0.0004\n",
       "book4_A_Feast_For_Crows  1.7689   0.1416 12.4915 0.0000  1.4914  2.0465\n",
       "mother_unknown           2.1798   0.6858  3.1786 0.0015  0.8357  3.5239\n",
       "age_unknown              0.7815   0.1505  5.1918 0.0000  0.4865  1.0766\n",
       "popularity_survive      -0.1067   0.0416 -2.5655 0.0103 -0.1881 -0.0252\n",
       "Order                   -0.0007   0.0001 -6.1332 0.0000 -0.0010 -0.0005\n",
       "=======================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logit_sig_2\n",
    "# instantiating a logistic regression model object\n",
    "logistic_small = smf.logit(formula   = \"\"\"isAlive~\n",
    "book1_A_Game_Of_Thrones + \n",
    "book2_A_Clash_Of_Kings + \n",
    "book4_A_Feast_For_Crows +   \n",
    "mother_unknown +  \n",
    "\n",
    "\n",
    "age_unknown+\n",
    "popularity_survive+\n",
    "Order\n",
    "\n",
    " \"\"\",\n",
    "                           data = GOT_train)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "results_logistic = logistic_small.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary2() # summary2() has AIC and BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc4415",
   "metadata": {},
   "source": [
    "# Classification- Logistic Regressions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9961b262",
   "metadata": {},
   "source": [
    "## Dictionary of all the above LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7fc29265",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.927381Z",
     "start_time": "2021-12-05T21:32:28.922472Z"
    }
   },
   "outputs": [],
   "source": [
    "# explanatory sets from last session\n",
    "\n",
    "# creating a dictionary to store candidate models\n",
    "\n",
    "candidate_dict = {\n",
    "\n",
    " # full model\n",
    " 'logit_full'   : ['Order' , 'book1_A_Game_Of_Thrones' , 'book2_A_Clash_Of_Kings' , \\\n",
    "                   'book3_A_Storm_Of_Swords' , 'book4_A_Feast_For_Crows' , 'book5_A_Dance_with_Dragons' ,\\\n",
    "                   'isMarried' , 'isNoble' , 'numDeadRelations' , 'popularity' , 'mother_unknown' ,\\\n",
    "                   'father_unknown' , 'house_unknown' , 'culture_unknown' , 'title_unknown' , \\\n",
    "                   'heir_unknown' , 'spouse_unknown' , 'age_unknown' , 'isAliveMother_unknown' , \\\n",
    "                   'isAliveFather_unknown' , 'isAliveHeir_unknown' , 'isAliveSpouse_unknown'], \n",
    "    \n",
    " 'logit_full_remove'   : ['Order' , 'book1_A_Game_Of_Thrones' , 'book2_A_Clash_Of_Kings' , \\\n",
    "                  'book3_A_Storm_Of_Swords','book4_A_Feast_For_Crows' , 'book5_A_Dance_with_Dragons' ,\\\n",
    "                    'numDeadRelations' , 'popularity' ,'culture_unknown' ,'isMarried', 'title_unknown' , \\\n",
    "                   'spouse_unknown' , 'age_unknown' , 'isAliveSpouse_unknown'],\n",
    "    #significant variables only (set 1)\n",
    " 'logit_full_reduced'    : ['Order' , 'book1_A_Game_Of_Thrones', 'book4_A_Feast_For_Crows',\\\n",
    "                          'mother_unknown','age_unknown','alive_books_longest'],\n",
    "    \n",
    " # significant variables only (set 1)\n",
    " 'logit_sig'    : ['Order' , 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings',\\\n",
    "                   'book4_A_Feast_For_Crows','numDeadRelations', 'mother_unknown','age_unknown'],\n",
    "    \n",
    "  \n",
    " # significant variables only (set 2)\n",
    " 'logit_sig_2'  : ['book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', 'book4_A_Feast_For_Crows',\\\n",
    "                   'mother_unknown', 'age_unknown', 'popularity_survive', 'Order'],\n",
    "\n",
    "                   \n",
    "    # mostly significant variables (set 3)\n",
    " 'logit_unsig_3'  : ['Order', 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings',\\\n",
    "                   'book4_A_Feast_For_Crows', 'numDeadRelations', 'mother_unknown',\\\n",
    "                     'familiarity_father_2','age_unknown'],     \n",
    "    \n",
    "    # significant variables only (without 'mother_unknown')\n",
    "     'logit_sig_2_1'  : ['book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', 'book4_A_Feast_For_Crows',\\\n",
    "                    'age_unknown', 'popularity_survive', 'Order'],\n",
    "    \n",
    "    # significant variables only, variation\n",
    "     'logit_sig_2_2'  : ['Order', 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings',\\\n",
    "                    'book4_A_Feast_For_Crows', 'numDeadRelations', 'mother_unknown', 'age_unknown'],\n",
    "    \n",
    "    # significant variables only (set 4)\n",
    " 'logit_sig_4'  : ['book4_A_Feast_For_Crows', 'age_unknown', 'father_unknown',\\\n",
    "                   'house_unknown', 'title_unknown'], \n",
    "    \n",
    "    # significant variables only (set 5)\n",
    " 'logit_sig_5'  : ['Order', 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings',\\\n",
    "                   'book4_A_Feast_For_Crows', 'numDeadRelations','popularity', 'alive_books_longest'],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ac05f57e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.931874Z",
     "start_time": "2021-12-05T21:32:28.928723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/--------------------------\\\n",
      "|Explanatory Variable Sets |\n",
      "\\--------------------------/\n",
      "\n",
      "Full Model:\n",
      "-----------\n",
      "['Order', 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', 'book3_A_Storm_Of_Swords', 'book4_A_Feast_For_Crows', 'book5_A_Dance_with_Dragons', 'isMarried', 'isNoble', 'numDeadRelations', 'popularity', 'mother_unknown', 'father_unknown', 'house_unknown', 'culture_unknown', 'title_unknown', 'heir_unknown', 'spouse_unknown', 'age_unknown', 'isAliveMother_unknown', 'isAliveFather_unknown', 'isAliveHeir_unknown', 'isAliveSpouse_unknown']\n",
      "\n",
      "Full Model Reduced:\n",
      "-----------\n",
      "['Order', 'book1_A_Game_Of_Thrones', 'book4_A_Feast_For_Crows', 'mother_unknown', 'age_unknown', 'alive_books_longest']\n",
      "\n",
      "First Significant p-value Model:\n",
      "--------------------------------\n",
      "['Order', 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', 'book4_A_Feast_For_Crows', 'numDeadRelations', 'mother_unknown', 'age_unknown']\n",
      "\n",
      "Second Significant p-value Model:\n",
      "---------------------------------\n",
      "['book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', 'book4_A_Feast_For_Crows', 'mother_unknown', 'age_unknown', 'popularity_survive', 'Order']\n",
      "\n",
      "Third mostly Significant p-value Model:\n",
      "-----------\n",
      "['Order', 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', 'book4_A_Feast_For_Crows', 'numDeadRelations', 'mother_unknown', 'familiarity_father_2', 'age_unknown']\n",
      "\n",
      "Second_First Significant p-value Model:\n",
      "--------------------------------\n",
      "['book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', 'book4_A_Feast_For_Crows', 'age_unknown', 'popularity_survive', 'Order']\n",
      "\n",
      "Second_Second Significant p-value Model:\n",
      "---------------------------------\n",
      "['Order', 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', 'book4_A_Feast_For_Crows', 'numDeadRelations', 'mother_unknown', 'age_unknown']\n",
      "\n",
      "Forth Significant p-value Model:\n",
      "---------------------------------\n",
      "['book4_A_Feast_For_Crows', 'age_unknown', 'father_unknown', 'house_unknown', 'title_unknown']\n",
      "\n",
      "Fifth Significant p-value Model:\n",
      "---------------------------------\n",
      "['Order', 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', 'book4_A_Feast_For_Crows', 'numDeadRelations', 'popularity', 'alive_books_longest']\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing candidate variable sets\n",
    "print(f\"\"\"\n",
    "/--------------------------\\\\\n",
    "|Explanatory Variable Sets |\n",
    "\\\\--------------------------/\n",
    "\n",
    "Full Model:\n",
    "-----------\n",
    "{candidate_dict['logit_full']}\n",
    "\n",
    "Full Model Reduced:\n",
    "-----------\n",
    "{candidate_dict['logit_full_reduced']}\n",
    "\n",
    "First Significant p-value Model:\n",
    "--------------------------------\n",
    "{candidate_dict['logit_sig']}\n",
    "\n",
    "Second Significant p-value Model:\n",
    "---------------------------------\n",
    "{candidate_dict['logit_sig_2']}\n",
    "\n",
    "Third mostly Significant p-value Model:\n",
    "-----------\n",
    "{candidate_dict['logit_unsig_3']}\n",
    "\n",
    "Second_First Significant p-value Model:\n",
    "--------------------------------\n",
    "{candidate_dict['logit_sig_2_1']}\n",
    "\n",
    "Second_Second Significant p-value Model:\n",
    "---------------------------------\n",
    "{candidate_dict['logit_sig_2_2']}\n",
    "\n",
    "Forth Significant p-value Model:\n",
    "---------------------------------\n",
    "{candidate_dict['logit_sig_4']}\n",
    "\n",
    "Fifth Significant p-value Model:\n",
    "---------------------------------\n",
    "{candidate_dict['logit_sig_5']}\n",
    "\n",
    "\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b462ee70",
   "metadata": {},
   "source": [
    "## Track of scores\n",
    "#Test all the dictionaries with the initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fc76e35f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:28.935332Z",
     "start_time": "2021-12-05T21:32:28.932932Z"
    }
   },
   "outputs": [],
   "source": [
    "# logit_full\n",
    "# Training Accuracy: 0.7847\n",
    "# Testing  Accuracy: 0.8564\n",
    "# AUC Score: 0.7462\n",
    "\n",
    "# logit_sig\n",
    "# Training Accuracy: 0.7778\n",
    "# Testing  Accuracy: 0.8513\n",
    "# AUC Score: 0.7362\n",
    "\n",
    "# logit_sig_2\n",
    "# C = 1\n",
    "# Training Accuracy: 0.7813\n",
    "# Testing  Accuracy: 0.8615\n",
    "# AUC Score: 0.7497\n",
    "\n",
    "# ********logit_sig_2\n",
    "# solver = 'lbfgs',\n",
    "# C = 2,\n",
    "# random_state = 219,\n",
    "# max_iter = 10000\n",
    "# Training Accuracy: 0.7727\n",
    "# Testing  Accuracy: 0.8615\n",
    "# AUC Score: 0.7562\n",
    "\n",
    "# logit_unsig_3\n",
    "# Training Accuracy: 0.7807\n",
    "# Testing  Accuracy: 0.8513\n",
    "# AUC Score: 0.7362\n",
    "\n",
    "#log_sig_4\n",
    "# Training Accuracy: 0.7841\n",
    "# Testing  Accuracy: 0.8205\n",
    "# AUC Score: 0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cea40d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T08:28:49.988063Z",
     "start_time": "2021-12-05T08:28:49.983839Z"
    }
   },
   "source": [
    "### Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67d35f56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.033258Z",
     "start_time": "2021-12-05T21:32:28.936589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7853\n",
      "Testing  Accuracy: 0.8564\n",
      "AUC Score: 0.7462\n"
     ]
    }
   ],
   "source": [
    "# train/test split with the full model\n",
    "GOT_data_2   =  GOT.loc[ : , candidate_dict['logit_full']]\n",
    "GOT_target =  GOT.loc[ : , 'isAlive']\n",
    "\n",
    "\n",
    "# This is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            GOT_data_2,\n",
    "            GOT_target,\n",
    "            test_size    = 0.10,\n",
    "            random_state = 219,\n",
    "            stratify     = GOT_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 2.0,\n",
    "                            random_state = 219,\n",
    "                            max_iter = 10000)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "# SCORING the results\n",
    "print('Training Accuracy:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  Accuracy:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "# area under the roc curve (auc)\n",
    "print('AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                    y_score = logreg_pred).round(decimals = 4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4) # accuracy\n",
    "\n",
    "# saving AUC score for future use\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5b314a",
   "metadata": {},
   "source": [
    "### Best variation from dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d59064c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.074374Z",
     "start_time": "2021-12-05T21:32:29.034337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7756\n",
      "Testing  Accuracy: 0.8615\n",
      "AUC Score: 0.7562\n"
     ]
    }
   ],
   "source": [
    "# train/test split with the full model\n",
    "GOT_data_2   =  GOT.loc[ : , candidate_dict['logit_sig_2']]\n",
    "GOT_target =  GOT.loc[ : , 'isAlive']\n",
    "\n",
    "\n",
    "# This is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            GOT_data_2,\n",
    "            GOT_target,\n",
    "            test_size    = 0.10,\n",
    "            random_state = 219,\n",
    "            stratify     = GOT_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 2.1,\n",
    "                            random_state = 219,\n",
    "                            max_iter = 10000)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "# SCORING the results\n",
    "print('Training Accuracy:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  Accuracy:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "# area under the roc curve (auc)\n",
    "print('AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                    y_score = logreg_pred).round(decimals = 4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4) # accuracy\n",
    "\n",
    "# saving AUC score for future use\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "07566158",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.079786Z",
     "start_time": "2021-12-05T21:32:29.075388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('intercept', 0.32)\n",
      "('book1_A_Game_Of_Thrones', -0.44)\n",
      "('book2_A_Clash_Of_Kings', -0.32)\n",
      "('book4_A_Feast_For_Crows', 1.77)\n",
      "('mother_unknown', 0.49)\n",
      "('age_unknown', 0.57)\n",
      "('popularity_survive', -0.16)\n",
      "('Order', -0.0)\n"
     ]
    }
   ],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "logreg_model_values = zip(GOT[candidate_dict['logit_sig_2']].columns,\n",
    "                          logreg_fit.coef_.ravel().round(decimals = 2))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "logreg_model_lst = [('intercept', logreg_fit.intercept_[0].round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in logreg_model_values:\n",
    "    logreg_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in logreg_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4ca25947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.083120Z",
     "start_time": "2021-12-05T21:32:29.080994Z"
    }
   },
   "outputs": [],
   "source": [
    "# # train/test split with the logit_sig variables\n",
    "# GOT_data_2   =  GOT.loc[:, candidate_dict['logit_sig_2']]\n",
    "# GOT_target =  GOT.loc[:,'isAlive']\n",
    "\n",
    "\n",
    "# # train/test split\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#             GOT_data_2,\n",
    "#             GOT_target,\n",
    "#             random_state = 219,\n",
    "#             test_size    = 0.1,\n",
    "#             stratify     = GOT_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fac057",
   "metadata": {},
   "source": [
    "## Tuning \n",
    "For the tuning, I decided to go with values that scikit learn suggested as good ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f7e555cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.087274Z",
     "start_time": "2021-12-05T21:32:29.084389Z"
    }
   },
   "outputs": [],
   "source": [
    "# ########################################\n",
    "# # RandomizedSearchCV\n",
    "# ########################################\n",
    "\n",
    "# # declaring a hyperparameter space\n",
    "# C_range          = np.arange(0.5, 6.0, 0.1)\n",
    "# warm_start_range = [True, False]\n",
    "# solver_range     = ['lbfgs']\n",
    "\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'C'          : C_range,\n",
    "#               'warm_start' : warm_start_range,\n",
    "#               'solver'     : solver_range}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# lr_tuned = LogisticRegression(random_state = 219,\n",
    "#                               max_iter     = 3000) # increased for convergence\n",
    "\n",
    "\n",
    "# # GridSearchCV object\n",
    "# lr_tuned_cv = RandomizedSearchCV(estimator           = lr_tuned,   # the model object\n",
    "#                                  param_distributions = param_grid, # parameters to tune\n",
    "#                                  cv                  = 3,          # how many folds in cross-validation\n",
    "#                                  n_iter              = 10000,        # number of combinations of hyperparameters to try\n",
    "#                                  random_state        = 219,        # starting point for random sequence\n",
    "#                                  scoring = make_scorer(\n",
    "#                                            roc_auc_score,\n",
    "#                                            needs_threshold = False)) # scoring criteria (AUC)\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# lr_tuned_cv.fit(GOT_data_2, GOT_target)\n",
    "\n",
    "\n",
    "# # PREDICT step is not needed\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", lr_tuned_cv.best_params_)\n",
    "# print(\"Tuned CV AUC      :\", lr_tuned_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cab1899b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.090296Z",
     "start_time": "2021-12-05T21:32:29.088510Z"
    }
   },
   "outputs": [],
   "source": [
    "# lr_tuned_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b81182",
   "metadata": {},
   "source": [
    "### Tuning 1-AUC Score: 0.7562"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "543f3508",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.125620Z",
     "start_time": "2021-12-05T21:32:29.091386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7727\n",
      "Testing  Accuracy: 0.8615\n",
      "AUC Score: 0.7562\n"
     ]
    }
   ],
   "source": [
    "# train/test split with the full model\n",
    "GOT_data   =  GOT.loc[ : , candidate_dict['logit_sig_2']]\n",
    "GOT_target =  GOT.loc[ : , 'isAlive']\n",
    "\n",
    "\n",
    "# This is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            GOT_data,\n",
    "            GOT_target,\n",
    "            test_size    = 0.10,\n",
    "            random_state = 219,\n",
    "            stratify     = GOT_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 2,\n",
    "                            warm_start=True,\n",
    "                            random_state = 219,\n",
    "                            max_iter = 3000)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "# SCORING the results\n",
    "print('Training Accuracy:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  Accuracy:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "# area under the roc curve (auc)\n",
    "print('AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                    y_score = logreg_pred).round(decimals = 4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4) # accuracy\n",
    "\n",
    "# saving AUC score for future use\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "188a62e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.130840Z",
     "start_time": "2021-12-05T21:32:29.127446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 27\n",
      "False Positives: 23\n",
      "False Negatives: 4\n",
      "True Positives : 141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test, y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0356e624",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.136089Z",
     "start_time": "2021-12-05T21:32:29.132203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model         AUC Score      TN, FP, FN, TP\n",
      "-----         ---------      --------------\n",
      "Logistic      0.7562         (27, 23, 4, 141)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comparing results\n",
    "print(f\"\"\"\n",
    "Model         AUC Score      TN, FP, FN, TP\n",
    "-----         ---------      --------------\n",
    "Logistic      {logreg_auc_score}         {logreg_tn, logreg_fp, logreg_fn, logreg_tp}\n",
    "\"\"\")\n",
    "# Full Tree     {full_tree_auc_score}           {full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp}\n",
    "# Pruned Tree   {pruned_tree_auc_score}         {pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp}\n",
    "\n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Name'    : ['Logistic'],\n",
    "           \n",
    "    'AUC Score' : [logreg_auc_score],\n",
    "    \n",
    "    'Training Accuracy' : [logreg_train_score],\n",
    "           \n",
    "    'Testing Accuracy'  : [logreg_test_score],\n",
    "\n",
    "    'Confusion Matrix'  : [(logreg_tn, logreg_fp, logreg_fn, logreg_tp)]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a55629",
   "metadata": {},
   "source": [
    "### Tuning 2-AUC Score: 0.7497"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ed2af5e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.140239Z",
     "start_time": "2021-12-05T21:32:29.137606Z"
    }
   },
   "outputs": [],
   "source": [
    "# # train/test split with the full model\n",
    "# GOT_data   =  GOT.loc[ : , candidate_dict['logit_sig_2']]\n",
    "# GOT_target =  GOT.loc[ : , 'isAlive']\n",
    "\n",
    "\n",
    "# # This is the exact code we were using before\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#             GOT_data,\n",
    "#             GOT_target,\n",
    "#             test_size    = 0.10,\n",
    "#             random_state = 219,\n",
    "#             stratify     = GOT_target)\n",
    "\n",
    "\n",
    "# # INSTANTIATING a logistic regression model\n",
    "# logreg = LogisticRegression(solver = 'lbfgs',\n",
    "#                             C = 4.3,\n",
    "#                             warm_start=True,\n",
    "#                             random_state = 219,\n",
    "#                             max_iter = 3000)\n",
    "\n",
    "\n",
    "# # FITTING the training data\n",
    "# logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "# # PREDICTING based on the testing set\n",
    "# logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "# # SCORING the results\n",
    "# print('Training Accuracy:', logreg_fit.score(x_train, y_train).round(4))\n",
    "# print('Testing  Accuracy:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "# # area under the roc curve (auc)\n",
    "# print('AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "#                     y_score = logreg_pred).round(decimals = 4))\n",
    "\n",
    "\n",
    "# # saving scoring data for future use\n",
    "# logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "# logreg_test_score  = logreg_fit.score(x_test, y_test).round(4) # accuracy\n",
    "\n",
    "# # saving AUC score for future use\n",
    "# logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "#                                  y_score = logreg_pred).round(decimals = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "61f2af24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.143535Z",
     "start_time": "2021-12-05T21:32:29.141453Z"
    }
   },
   "outputs": [],
   "source": [
    "# lr_tuned_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165f7053",
   "metadata": {},
   "source": [
    "### Tuning 2-AUC Score: 0.7397"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ef7662f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.147161Z",
     "start_time": "2021-12-05T21:32:29.144576Z"
    }
   },
   "outputs": [],
   "source": [
    "# # train/test split with the full model\n",
    "# GOT_data   =  GOT.loc[ : , candidate_dict['logit_sig_2']]\n",
    "# GOT_target =  GOT.loc[ : , 'isAlive']\n",
    "\n",
    "\n",
    "# # This is the exact code we were using before\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#             GOT_data,\n",
    "#             GOT_target,\n",
    "#             test_size    = 0.10,\n",
    "#             random_state = 219,\n",
    "#             stratify     = GOT_target)\n",
    "\n",
    "\n",
    "# # INSTANTIATING a logistic regression model\n",
    "# logreg = LogisticRegression(solver = 'newton-cg',\n",
    "#                             C = 0.4,\n",
    "#                             warm_start=True,\n",
    "#                             random_state = 219,\n",
    "#                             max_iter = 3000)\n",
    "\n",
    "\n",
    "# # FITTING the training data\n",
    "# logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "# # PREDICTING based on the testing set\n",
    "# logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "# # SCORING the results\n",
    "# print('Training Accuracy:', logreg_fit.score(x_train, y_train).round(4))\n",
    "# print('Testing  Accuracy:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "# # area under the roc curve (auc)\n",
    "# print('AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "#                     y_score = logreg_pred).round(decimals = 4))\n",
    "\n",
    "\n",
    "# # saving scoring data for future use\n",
    "# logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "# logreg_test_score  = logreg_fit.score(x_test, y_test).round(4) # accuracy\n",
    "\n",
    "# # saving AUC score for future use\n",
    "# logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "#                                  y_score = logreg_pred).round(decimals = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4febc059",
   "metadata": {},
   "source": [
    "# Cart model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9a1d9d72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.151748Z",
     "start_time": "2021-12-05T21:32:29.148308Z"
    }
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = x_train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('Tree_Leaf_50_Feature_Importance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d16ebc4",
   "metadata": {},
   "source": [
    "# Full Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0c008190",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.169207Z",
     "start_time": "2021-12-05T21:32:29.152867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Tree Training ACCURACY: 1.0\n",
      "Full Tree Testing ACCURACY : 0.7333\n",
      "Full Tree AUC Score: 0.6766\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "full_tree_fit = full_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "full_tree_pred = full_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Full Tree Training ACCURACY:', full_tree_fit.score(x_train,\n",
    "                                                     y_train).round(4))\n",
    "\n",
    "print('Full Tree Testing ACCURACY :', full_tree_fit.score(x_test,\n",
    "                                                     y_test).round(4))\n",
    "\n",
    "print('Full Tree AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                                            y_score = full_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "full_tree_train_score = full_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "full_tree_test_score  = full_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving AUC\n",
    "full_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                      y_score = full_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c61df4bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.174306Z",
     "start_time": "2021-12-05T21:32:29.170754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 28\n",
      "False Positives: 22\n",
      "False Negatives: 30\n",
      "True Positives : 115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "full_tree_tn, \\\n",
    "full_tree_fp, \\\n",
    "full_tree_fn, \\\n",
    "full_tree_tp = confusion_matrix(y_true = y_test, y_pred = full_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {full_tree_tn}\n",
    "False Positives: {full_tree_fp}\n",
    "False Negatives: {full_tree_fn}\n",
    "True Positives : {full_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "24bb4f96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.188210Z",
     "start_time": "2021-12-05T21:32:29.175711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>(27, 23, 4, 141)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6766</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>(28, 22, 30, 115)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "0   Logistic     0.7562             0.7727            0.8615   (27, 23, 4, 141)\n",
       "1  Full Tree     0.6766             1.0000            0.7333  (28, 22, 30, 115)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "full_tree_train_score = full_tree_fit.score(x_train, y_train).round(4)\n",
    "full_tree_test_score  = full_tree_fit.score(x_test, y_test).round(4)\n",
    "full_tree_auc_score       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = full_tree_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'         : 'Full Tree',\n",
    "                           'Training Accuracy'  : full_tree_train_score,\n",
    "                           'Testing Accuracy'   : full_tree_test_score,\n",
    "                           'AUC Score'          : full_tree_auc_score,\n",
    "                           'Confusion Matrix'   : (full_tree_tn,\n",
    "                                                   full_tree_fp,\n",
    "                                                   full_tree_fn,\n",
    "                                                   full_tree_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb88340b",
   "metadata": {},
   "source": [
    "# Pruned Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0588107b",
   "metadata": {},
   "source": [
    "## General settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "37a7d924",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.225173Z",
     "start_time": "2021-12-05T21:32:29.210119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8058\n",
      "Testing  ACCURACY: 0.841\n",
      "AUC Score        : 0.7359\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "tree_pruned = DecisionTreeClassifier(max_depth=6.9,\n",
    "                    min_samples_leaf=24,\n",
    "                    random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "tree_pruned_fit = tree_pruned.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "tree_pruned_predict = tree_pruned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', tree_pruned_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_pruned_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_pruned_predict).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = tree_pruned_fit.score(x_train, y_train).round(4) # accuracy\n",
    "pruned_tree_test_score  = tree_pruned_fit.score(x_test, y_test).round(4) # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = tree_pruned_predict).round(4) # auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2543181",
   "metadata": {},
   "source": [
    "## Tuning\n",
    "For the tuning, I decided to go with values that scikit learn suggested as good ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a6b69c0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.229634Z",
     "start_time": "2021-12-05T21:32:29.226521Z"
    }
   },
   "outputs": [],
   "source": [
    "# # declaring a hyperparameter space\n",
    "# criterion_range=[\"gini\",\"entropy\"]\n",
    "# max_depth_range= np.arange(0.1,8,0.1)\n",
    "# splitter_range= [\"random\"]\n",
    "# min_samples_split_range=np.arange(2,7,1)\n",
    "\n",
    "# # depth range and leaf range\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'criterion'          : criterion_range,\n",
    "#              'max_depth'          : max_depth_range,\n",
    "#              'splitter'          : splitter_range,\n",
    "#              'min_samples_split':min_samples_split_range}\n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# lr_tuned = DecisionTreeClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "\n",
    "# # RandomizedSearchCV object\n",
    "# lr_tuned_cv = RandomizedSearchCV(estimator           = lr_tuned,   # the model object\n",
    "#                                  param_distributions = param_grid, # parameters to tune\n",
    "#                                  cv                  = 3,          # how many folds in cross-validation\n",
    "#                                  n_iter              = 250,        # number of combinations of hyperparameters to try\n",
    "#                                  random_state        = 219,        # starting point for random sequence\n",
    "#                                  scoring = make_scorer(\n",
    "#                                            roc_auc_score,\n",
    "#                                            needs_threshold = False))\n",
    "\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# lr_tuned_cv.fit(GOT_data_2, GOT_target)\n",
    "\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "\n",
    "# print(\"Tuned Parameters  :\", lr_tuned_cv.best_params_)\n",
    "# print(\"Tuned CV AUC      :\", lr_tuned_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dfda56",
   "metadata": {},
   "source": [
    "## Best try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "59bb3a34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.245636Z",
     "start_time": "2021-12-05T21:32:29.230938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.803\n",
      "Testing  ACCURACY: 0.8718\n",
      "AUC Score        : 0.7631\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "tree_pruned = DecisionTreeClassifier(max_depth=6.1,\n",
    "                                     splitter='random',\n",
    "                           min_samples_split=5,         \n",
    "                    criterion='gini',\n",
    "                    random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "tree_pruned_fit = tree_pruned.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "tree_pruned_predict = tree_pruned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', tree_pruned_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_pruned_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_pruned_predict).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = tree_pruned_fit.score(x_train, y_train).round(4) # accuracy\n",
    "pruned_tree_test_score  = tree_pruned_fit.score(x_test, y_test).round(4) # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = tree_pruned_predict).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dd35f7e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.251024Z",
     "start_time": "2021-12-05T21:32:29.247076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 27\n",
      "False Positives: 23\n",
      "False Negatives: 2\n",
      "True Positives : 143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test, y_pred = tree_pruned_predict).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {pruned_tree_tn}\n",
    "False Positives: {pruned_tree_fp}\n",
    "False Negatives: {pruned_tree_fn}\n",
    "True Positives : {pruned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "38615c7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.264667Z",
     "start_time": "2021-12-05T21:32:29.252258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>(27, 23, 4, 141)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6766</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>(28, 22, 30, 115)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.8718</td>\n",
       "      <td>(27, 23, 2, 143)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "0     Logistic     0.7562             0.7727            0.8615   (27, 23, 4, 141)\n",
       "1    Full Tree     0.6766             1.0000            0.7333  (28, 22, 30, 115)\n",
       "2  Pruned Tree     0.7631             0.8030            0.8718   (27, 23, 2, 143)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "pruned_tree_train_score = tree_pruned_fit.score(x_train, y_train).round(4)\n",
    "pruned_tree_test_score  = tree_pruned_fit.score(x_test, y_test).round(4)\n",
    "pruned_tree_auc_score       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = tree_pruned_predict).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'         : 'Pruned Tree',\n",
    "                           'Training Accuracy'  : pruned_tree_train_score,\n",
    "                           'Testing Accuracy'   : pruned_tree_test_score,\n",
    "                           'AUC Score'          : pruned_tree_auc_score,\n",
    "                           'Confusion Matrix'   : (pruned_tree_tn,\n",
    "                                                   pruned_tree_fp,\n",
    "                                                   pruned_tree_fn,\n",
    "                                                   pruned_tree_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9a254ab6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.268378Z",
     "start_time": "2021-12-05T21:32:29.265842Z"
    }
   },
   "outputs": [],
   "source": [
    "# # INSTANTIATING a classification tree object\n",
    "# tree_pruned = DecisionTreeClassifier(max_depth=6.8,\n",
    "#                     min_samples_leaf=3,\n",
    "#                     splitter= 'random',\n",
    "#                     criterion= 'gini',\n",
    "#                     random_state = 219)\n",
    "\n",
    "\n",
    "# # FITTING the training data\n",
    "# tree_pruned_fit = tree_pruned.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# # PREDICTING on new data\n",
    "# tree_pruned_predict = tree_pruned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# # SCORING the model\n",
    "# print('Training ACCURACY:', tree_pruned_fit.score(x_train, y_train).round(4))\n",
    "# print('Testing  ACCURACY:', tree_pruned_fit.score(x_test, y_test).round(4))\n",
    "# print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "#                                           y_score = tree_pruned_predict).round(4))\n",
    "\n",
    "\n",
    "# # saving scoring data for future use\n",
    "# pruned_tree_train_score = tree_pruned_fit.score(x_train, y_train).round(4) # accuracy\n",
    "# pruned_tree_test_score  = tree_pruned_fit.score(x_test, y_test).round(4) # accuracy\n",
    "\n",
    "\n",
    "# # saving auc score\n",
    "# pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "#                                         y_score = tree_pruned_predict).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9b8ed733",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.272920Z",
     "start_time": "2021-12-05T21:32:29.269730Z"
    }
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('./analysis_images/Feature_Importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "be96d99d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.275761Z",
     "start_time": "2021-12-05T21:32:29.273904Z"
    }
   },
   "outputs": [],
   "source": [
    "# # train/test split with the logit_sig variables\n",
    "# GOT_data_2   =  GOT.loc[:,candidate_dict['logit_full']]\n",
    "# GOT_target =  GOT.loc[:,'isAlive']\n",
    "\n",
    "\n",
    "# # train/test split\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#             GOT_data_2,\n",
    "#             GOT_target,\n",
    "#             random_state = 219,\n",
    "#             test_size    = 0.10,\n",
    "#             stratify     = GOT_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41647d70",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea384fe",
   "metadata": {},
   "source": [
    "## Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "98ff8c66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.279182Z",
     "start_time": "2021-12-05T21:32:29.276850Z"
    }
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a random forest model with default values\n",
    "rf_default = RandomForestClassifier(n_estimators     = 100,\n",
    "                                    criterion        = 'gini',\n",
    "                                    max_depth        = 4,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = False,\n",
    "                                    random_state     = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6f3a5180",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.417216Z",
     "start_time": "2021-12-05T21:32:29.280564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7973\n",
      "Testing  ACCURACY: 0.8462\n",
      "AUC Score        : 0.7\n"
     ]
    }
   ],
   "source": [
    "# FITTING the training data\n",
    "rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', rf_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b91e4d",
   "metadata": {},
   "source": [
    "## Tuning\n",
    "For the tuning, I decided to go with values that scikit learn suggested as good ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9e00646d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.420646Z",
     "start_time": "2021-12-05T21:32:29.418161Z"
    }
   },
   "outputs": [],
   "source": [
    "# # FITTING the training data\n",
    "# rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# # PREDICTING based on the testing set\n",
    "# rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# # declaring a hyperparameter space\n",
    "# estimator_range  = np.arange(100, 1100, 250)\n",
    "# max_depth_range= np. arange(3,6,0.1)\n",
    "# leaf_range       = np.arange(10, 35, 5)\n",
    "# criterion_range  = ['gini', 'entropy']\n",
    "# bootstrap_range  = [True, False]\n",
    "# warm_start_range = [True, False]\n",
    "\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'n_estimators'     : estimator_range,\n",
    "#               'max_depth'         :max_depth_range,\n",
    "#               'min_samples_leaf'  : leaf_range,\n",
    "#               'criterion'        : criterion_range,\n",
    "#               'bootstrap'        : bootstrap_range,\n",
    "#               'warm_start'       : warm_start_range}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# forest_grid = RandomForestClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# # GridSearchCV object\n",
    "# forest_cv = RandomizedSearchCV(estimator           = forest_grid,\n",
    "#                                param_distributions = param_grid,\n",
    "#                                cv         = 3,\n",
    "#                                n_iter     = 1000,\n",
    "#                                scoring    = make_scorer(roc_auc_score,\n",
    "#                                             needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# forest_cv.fit(GOT_data_2, GOT_target)\n",
    "\n",
    "\n",
    "# # PREDICT step is not needed\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", forest_cv.best_params_)\n",
    "# print(\"Tuned Training AUC:\", forest_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aa65e62a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:29.423495Z",
     "start_time": "2021-12-05T21:32:29.421829Z"
    }
   },
   "outputs": [],
   "source": [
    "#forest_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "415846e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:30.662515Z",
     "start_time": "2021-12-05T21:32:29.424558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Tuned Training ACCURACY: 0.7973\n",
      "Forest Tuned Testing  ACCURACY: 0.8718\n",
      "Forest Tuned AUC Score        : 0.75\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING with best_estimator\n",
    "forest_tuned = RandomForestClassifier(criterion= 'gini',\n",
    "                                     min_samples_leaf=30,\n",
    "                                       n_estimators=850,\n",
    "                                      random_state=219, \n",
    "                                      warm_start=True,\n",
    "                                      max_depth=5,\n",
    "                                      bootstrap= True\n",
    "                                     )\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "forest_tuned_fit = forest_tuned.fit(GOT_data_2, GOT_target)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "forest_tuned_pred = forest_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Forest Tuned Training ACCURACY:', forest_tuned.score(x_train, y_train).round(4))\n",
    "print('Forest Tuned Testing  ACCURACY:', forest_tuned.score(x_test, y_test).round(4))\n",
    "print('Forest Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                                       y_score = forest_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "forest_tuned_train_score = forest_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "forest_tuned_test_score  = forest_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score?\n",
    "forest_tuned_auc = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = forest_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b73cdfd",
   "metadata": {},
   "source": [
    "# Gradient Boosted Machines\n",
    "For the tuning, I decided to go with values that scikit learn suggested as good ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5a2f1d66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:30.666077Z",
     "start_time": "2021-12-05T21:32:30.663718Z"
    }
   },
   "outputs": [],
   "source": [
    "# # declaring a hyperparameter space\n",
    "# learn_range        = np.arange(0.1, 0.5, 0.01)\n",
    "# estimator_range    = np.arange(40, 60, 1)\n",
    "# depth_range        = np.arange(2, 8, 2)\n",
    "# warm_start_range   = [True, False]\n",
    "# loss_range         = ['deviance', 'exponential']\n",
    "# criterion_range    =  ['friedman_mse','mse']\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'learning_rate' : learn_range,\n",
    "#               'max_depth'     : depth_range,\n",
    "#               'n_estimators'  : estimator_range,\n",
    "#               'warm_start'    : warm_start_range,\n",
    "#              'loss'            : loss_range,\n",
    "#              'criterion'        : criterion_range}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# full_gbm_grid = GradientBoostingClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# # GridSearchCV object\n",
    "# full_gbm_cv = RandomizedSearchCV(estimator     = full_gbm_grid,\n",
    "#                            param_distributions = param_grid,\n",
    "#                            cv                  = 3,\n",
    "#                            n_iter              = 900,\n",
    "#                            random_state        = 219,\n",
    "#                            scoring             = make_scorer(roc_auc_score,\n",
    "#                                                  needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# full_gbm_cv.fit(GOT_data_2, GOT_target)\n",
    "\n",
    "\n",
    "# # PREDICT step is not needed\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", full_gbm_cv.best_params_)\n",
    "# print(\"Tuned Training AUC:\", full_gbm_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc54fcf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T09:05:22.925567Z",
     "start_time": "2021-12-05T09:05:22.920768Z"
    }
   },
   "source": [
    "## Full dataset after Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8fb0dbb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:30.672024Z",
     "start_time": "2021-12-05T21:32:30.666970Z"
    }
   },
   "outputs": [],
   "source": [
    "GOT_data_2= GOT.loc[:, candidate_dict['logit_full']]\n",
    "\n",
    "# This is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            GOT_data_2,\n",
    "            GOT_target,\n",
    "            test_size    = 0.10,\n",
    "            random_state = 219,\n",
    "            stratify     = GOT_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "524052ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:30.675266Z",
     "start_time": "2021-12-05T21:32:30.673225Z"
    }
   },
   "outputs": [],
   "source": [
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# full_gbm_default = GradientBoostingClassifier(loss          = 'deviance',\n",
    "#                                               learning_rate = 0.1,\n",
    "#                                               n_estimators  = 100,\n",
    "#                                               criterion     = 'friedman_mse',\n",
    "#                                               max_depth     = 3,\n",
    "#                                               warm_start    = False,\n",
    "#                                               random_state  = 219)\n",
    "\n",
    "\n",
    "# # FIT step is needed as we are not using .best_estimator\n",
    "# full_gbm_default_fit = full_gbm_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# # PREDICTING based on the testing set\n",
    "# full_gbm_default_pred = full_gbm_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# # SCORING the results\n",
    "# print('Training ACCURACY:', full_gbm_default_fit.score(x_train, y_train).round(4))\n",
    "# print('Testing ACCURACY :', full_gbm_default_fit.score(x_test, y_test).round(4))\n",
    "# print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "#                                           y_score = full_gbm_default_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9878338e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:30.732107Z",
     "start_time": "2021-12-05T21:32:30.676198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8013\n",
      "Testing ACCURACY : 0.8923\n",
      "AUC Score        : 0.8228\n"
     ]
    }
   ],
   "source": [
    "#Best score\n",
    "full_gbm = GradientBoostingClassifier(loss          = 'deviance',\n",
    "                                              learning_rate = 0.41, \n",
    "                                              n_estimators  = 68,\n",
    "                                              criterion     = 'friedman_mse',\n",
    "                                              max_depth     = 1,\n",
    "                                              warm_start    = True,\n",
    "                                              random_state  = 219)\n",
    "\n",
    "\n",
    "# FIT step is needed as we are not using .best_estimator\n",
    "full_gbm_fit = full_gbm.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "full_gbm_pred = full_gbm_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', full_gbm_fit.score(x_train, y_train).round(4))\n",
    "print('Testing ACCURACY :', full_gbm_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_gbm_pred).round(4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9c7d9923",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:30.735181Z",
     "start_time": "2021-12-05T21:32:30.733017Z"
    }
   },
   "outputs": [],
   "source": [
    "#second best score\n",
    "# Training ACCURACY: 0.7961\n",
    "# Testing ACCURACY : 0.8872\n",
    "# AUC Score        : 0.8128\n",
    "\n",
    "# full_gbm = GradientBoostingClassifier(loss          = 'exponential',\n",
    "#                                               learning_rate = 0.28,\n",
    "#                                               n_estimators  = 62,\n",
    "#                                               criterion     = 'friedman_mse',\n",
    "#                                               max_depth     = 1,\n",
    "#                                               warm_start    = True,\n",
    "#                                               random_state  = 219)\n",
    "\n",
    "\n",
    "# # FIT step is needed as we are not using .best_estimator\n",
    "# full_gbm_fit = full_gbm.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# # PREDICTING based on the testing set\n",
    "# full_gbm_pred = full_gbm_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# # SCORING the results\n",
    "# print('Training ACCURACY:', full_gbm_fit.score(x_train, y_train).round(4))\n",
    "# print('Testing ACCURACY :', full_gbm_fit.score(x_test, y_test).round(4))\n",
    "# print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "#                                           y_score = full_gbm_pred).round(4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "645feee8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:30.738269Z",
     "start_time": "2021-12-05T21:32:30.736273Z"
    }
   },
   "outputs": [],
   "source": [
    "#Third best score\n",
    "\n",
    "# Training ACCURACY: 0.8178\n",
    "# Testing ACCURACY : 0.8821\n",
    "# AUC Score        : 0.7962\n",
    "\n",
    "# full_gbm = GradientBoostingClassifier(loss          = 'deviance',\n",
    "#                                               learning_rate = 0.2,\n",
    "#                                               n_estimators  = 45,\n",
    "#                                               criterion     = 'friedman_mse',\n",
    "#                                               max_depth     = 2,\n",
    "#                                               warm_start    = True,\n",
    "#                                               random_state  = 219)\n",
    "\n",
    "\n",
    "# # FIT step is needed as we are not using .best_estimator\n",
    "# full_gbm_fit = full_gbm.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# # PREDICTING based on the testing set\n",
    "# full_gbm_pred = full_gbm_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# # SCORING the results\n",
    "# print('Training ACCURACY:', full_gbm_fit.score(x_train, y_train).round(4))\n",
    "# print('Testing ACCURACY :', full_gbm_fit.score(x_test, y_test).round(4))\n",
    "# print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "#                                           y_score = full_gbm_pred).round(4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "edf435e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:30.742846Z",
     "start_time": "2021-12-05T21:32:30.739281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 34\n",
      "False Positives: 16\n",
      "False Negatives: 5\n",
      "True Positives : 140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_tn, \\\n",
    "gbm_fp, \\\n",
    "gbm_fn, \\\n",
    "gbm_tp = confusion_matrix(y_true = y_test, y_pred = full_gbm_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_tn}\n",
    "False Positives: {gbm_fp}\n",
    "False Negatives: {gbm_fn}\n",
    "True Positives : {gbm_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "097c11aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:30.757841Z",
     "start_time": "2021-12-05T21:32:30.743723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>(27, 23, 4, 141)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6766</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>(28, 22, 30, 115)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.8718</td>\n",
       "      <td>(27, 23, 2, 143)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GBM (Full) [Final]</td>\n",
       "      <td>0.8228</td>\n",
       "      <td>0.8013</td>\n",
       "      <td>0.8923</td>\n",
       "      <td>(34, 16, 5, 140)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "0            Logistic     0.7562             0.7727            0.8615   (27, 23, 4, 141)\n",
       "1           Full Tree     0.6766             1.0000            0.7333  (28, 22, 30, 115)\n",
       "2         Pruned Tree     0.7631             0.8030            0.8718   (27, 23, 2, 143)\n",
       "3  GBM (Full) [Final]     0.8228             0.8013            0.8923   (34, 16, 5, 140)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "gbm_train_acc = full_gbm_fit.score(x_train, y_train).round(4)\n",
    "gbm_test_acc  = full_gbm_fit.score(x_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = full_gbm_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'       : 'GBM (Full) [Final]',\n",
    "                          'Training Accuracy' : gbm_train_acc,\n",
    "                          'Testing Accuracy'  : gbm_test_acc,\n",
    "                          'AUC Score'         : gbm_auc,\n",
    "                          'Confusion Matrix'  : (gbm_tn,\n",
    "                                                 gbm_fp,\n",
    "                                                 gbm_fn,\n",
    "                                                 gbm_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ef403c",
   "metadata": {},
   "source": [
    "## Reduced full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "26e8ea0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:30.763659Z",
     "start_time": "2021-12-05T21:32:30.758856Z"
    }
   },
   "outputs": [],
   "source": [
    "# explanatory sets from last session\n",
    "\n",
    "# creating a dictionary to store candidate models\n",
    "\n",
    "candidate_dict = {\n",
    "\n",
    " # full model\n",
    " 'logit_full'   : ['Order' , 'book1_A_Game_Of_Thrones' , 'book2_A_Clash_Of_Kings' , \\\n",
    "                   'book3_A_Storm_Of_Swords' , 'book4_A_Feast_For_Crows' , 'book5_A_Dance_with_Dragons' ,\\\n",
    "                   'isMarried' , 'isNoble' , 'numDeadRelations' , 'popularity' , 'mother_unknown' ,\\\n",
    "                   'father_unknown' , 'house_unknown' , 'culture_unknown' , 'title_unknown' , \\\n",
    "                   'heir_unknown' , 'spouse_unknown' , 'age_unknown' , 'isAliveMother_unknown' , \\\n",
    "                   'isAliveFather_unknown' , 'isAliveHeir_unknown' , 'isAliveSpouse_unknown'], \n",
    "    # full model\n",
    " 'logit_full_remove'   : ['Order' , 'book1_A_Game_Of_Thrones' , 'book2_A_Clash_Of_Kings' , \\\n",
    "                  'book3_A_Storm_Of_Swords','book4_A_Feast_For_Crows' , 'book5_A_Dance_with_Dragons' ,\\\n",
    "                    'numDeadRelations' , 'popularity' ,'culture_unknown' ,'isMarried', 'title_unknown' , \\\n",
    "                   'spouse_unknown' , 'age_unknown' , 'isAliveSpouse_unknown'], \n",
    "    \n",
    " # significant variables only (set 1)\n",
    " 'logit_full_reduced'    : ['Order' , 'book1_A_Game_Of_Thrones', 'book4_A_Feast_For_Crows',\\\n",
    "                          'mother_unknown','age_unknown','alive_books_longest'],\n",
    "    \n",
    " # significant variables only (set 1)\n",
    " 'logit_sig'    : ['Order' , 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings',\\\n",
    "                   'book4_A_Feast_For_Crows','numDeadRelations', 'mother_unknown','age_unknown'],\n",
    "    \n",
    "  \n",
    " # significant variables only (set 2)\n",
    " 'logit_sig_2'  : ['book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', 'book4_A_Feast_For_Crows',\\\n",
    "                   'mother_unknown', 'age_unknown', 'popularity_survive', 'Order'],\n",
    "\n",
    "                   \n",
    "    # mostly significant variables (set 3)\n",
    " 'logit_unsig_3'  : ['Order', 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings',\\\n",
    "                   'book4_A_Feast_For_Crows', 'numDeadRelations', 'mother_unknown',\\\n",
    "                     'familiarity_father_2','age_unknown'],     \n",
    "    \n",
    "    # significant variables only (without 'mother_unknown')\n",
    "     'logit_sig_2_1'  : ['book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', 'book4_A_Feast_For_Crows',\\\n",
    "                    'age_unknown', 'popularity_survive', 'Order'],\n",
    "    # significant variables only (without 'mother_unknown')\n",
    "     'logit_sig_2_2'  : ['Order', 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings',\\\n",
    "                    'book4_A_Feast_For_Crows', 'numDeadRelations', 'mother_unknown', 'age_unknown'],\n",
    "    \n",
    "    # significant variables only (set 2)\n",
    " 'logit_sig_4'  : ['book4_A_Feast_For_Crows', 'age_unknown', 'father_unknown',\\\n",
    "                   'house_unknown', 'title_unknown'],                                   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8d0964cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:30.824264Z",
     "start_time": "2021-12-05T21:32:30.764627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8395\n",
      "Testing ACCURACY : 0.8615\n",
      "AUC Score        : 0.789\n"
     ]
    }
   ],
   "source": [
    "GOT_data_2= GOT.loc[:, candidate_dict['logit_full_remove']]\n",
    "\n",
    "# This is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            GOT_data_2,\n",
    "            GOT_target,\n",
    "            test_size    = 0.10,\n",
    "            random_state = 219,\n",
    "            stratify     = GOT_target)\n",
    "full_gbm_remove = GradientBoostingClassifier(loss          = 'deviance',\n",
    "                                              learning_rate = 0.45,\n",
    "                                              n_estimators  = 48,\n",
    "                                              criterion     = 'friedman_mse',\n",
    "                                              max_depth     = 2,\n",
    "                                              warm_start    = True,\n",
    "                                              random_state  = 219)\n",
    "\n",
    "\n",
    "# FIT step is needed as we are not using .best_estimator\n",
    "full_gbm_remove_fit = full_gbm_remove.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "full_gbm_remove_pred = full_gbm_remove_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', full_gbm_remove_fit.score(x_train, y_train).round(4))\n",
    "print('Testing ACCURACY :', full_gbm_remove_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_gbm_remove_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5ad43682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:30.829364Z",
     "start_time": "2021-12-05T21:32:30.825234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 32\n",
      "False Positives: 18\n",
      "False Negatives: 9\n",
      "True Positives : 136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_remove_tn, \\\n",
    "gbm_remove_fp, \\\n",
    "gbm_remove_fn, \\\n",
    "gbm_remove_tp = confusion_matrix(y_true = y_test, y_pred = full_gbm_remove_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_remove_tn}\n",
    "False Positives: {gbm_remove_fp}\n",
    "False Negatives: {gbm_remove_fn}\n",
    "True Positives : {gbm_remove_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a0354273",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:30.844741Z",
     "start_time": "2021-12-05T21:32:30.830318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>(27, 23, 4, 141)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6766</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>(28, 22, 30, 115)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.8718</td>\n",
       "      <td>(27, 23, 2, 143)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GBM (Full) [Final]</td>\n",
       "      <td>0.8228</td>\n",
       "      <td>0.8013</td>\n",
       "      <td>0.8923</td>\n",
       "      <td>(34, 16, 5, 140)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBM (Full_removed)</td>\n",
       "      <td>0.7890</td>\n",
       "      <td>0.8395</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>(32, 18, 9, 136)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "0            Logistic     0.7562             0.7727            0.8615   (27, 23, 4, 141)\n",
       "1           Full Tree     0.6766             1.0000            0.7333  (28, 22, 30, 115)\n",
       "2         Pruned Tree     0.7631             0.8030            0.8718   (27, 23, 2, 143)\n",
       "3  GBM (Full) [Final]     0.8228             0.8013            0.8923   (34, 16, 5, 140)\n",
       "4  GBM (Full_removed)     0.7890             0.8395            0.8615   (32, 18, 9, 136)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "gbm_remove_train_acc = full_gbm_remove_fit.score(x_train, y_train).round(4)\n",
    "gbm_remove_test_acc  = full_gbm_remove_fit.score(x_test, y_test).round(4)\n",
    "gbm_remove_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = full_gbm_remove_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'       : 'GBM (Full_removed)',\n",
    "                          'Training Accuracy' : gbm_remove_train_acc,\n",
    "                          'Testing Accuracy'  : gbm_remove_test_acc,\n",
    "                          'AUC Score'         : gbm_remove_auc,\n",
    "                          'Confusion Matrix'  : (gbm_remove_tn,\n",
    "                                                 gbm_remove_fp,\n",
    "                                                 gbm_remove_fn,\n",
    "                                                 gbm_remove_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03365cff",
   "metadata": {},
   "source": [
    "## Sig_2_2_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "764f4505",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:30.923282Z",
     "start_time": "2021-12-05T21:32:30.845715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8698\n",
      "Testing ACCURACY : 0.8615\n",
      "AUC Score        : 0.789\n"
     ]
    }
   ],
   "source": [
    "GOT_data_2= GOT.loc[:, candidate_dict['logit_sig_2_2']]\n",
    "\n",
    "# This is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            GOT_data_2,\n",
    "            GOT_target,\n",
    "            test_size    = 0.10,\n",
    "            random_state = 219,\n",
    "            stratify     = GOT_target)\n",
    "full_gbm_sig = GradientBoostingClassifier(loss          = 'deviance',\n",
    "                                              learning_rate = 0.22,\n",
    "                                              n_estimators  = 50,\n",
    "                                              criterion     = 'friedman_mse',\n",
    "                                              max_depth     = 4,\n",
    "                                              warm_start    = True,\n",
    "                                              random_state  = 219)\n",
    "\n",
    "\n",
    "# FIT step is needed as we are not using .best_estimator\n",
    "full_gbm_sig_fit = full_gbm_sig.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "full_gbm_sig_pred = full_gbm_sig_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', full_gbm_sig_fit.score(x_train, y_train).round(4))\n",
    "print('Testing ACCURACY :', full_gbm_sig_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_gbm_sig_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "30b73669",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:30.927627Z",
     "start_time": "2021-12-05T21:32:30.924295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 32\n",
      "False Positives: 18\n",
      "False Negatives: 9\n",
      "True Positives : 136\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_sig_tn, \\\n",
    "gbm_sig_fp, \\\n",
    "gbm_sig_fn, \\\n",
    "gbm_sig_tp = confusion_matrix(y_true = y_test, y_pred = full_gbm_sig_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_sig_tn}\n",
    "False Positives: {gbm_sig_fp}\n",
    "False Negatives: {gbm_sig_fn}\n",
    "True Positives : {gbm_sig_tp}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "73115d3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:30.943480Z",
     "start_time": "2021-12-05T21:32:30.928608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>(27, 23, 4, 141)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6766</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>(28, 22, 30, 115)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.8718</td>\n",
       "      <td>(27, 23, 2, 143)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GBM (Full) [Final]</td>\n",
       "      <td>0.8228</td>\n",
       "      <td>0.8013</td>\n",
       "      <td>0.8923</td>\n",
       "      <td>(34, 16, 5, 140)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBM (Full_removed)</td>\n",
       "      <td>0.7890</td>\n",
       "      <td>0.8395</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>(32, 18, 9, 136)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GBM (sig)</td>\n",
       "      <td>0.7890</td>\n",
       "      <td>0.8698</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>(32, 18, 9, 136)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "0            Logistic     0.7562             0.7727            0.8615   (27, 23, 4, 141)\n",
       "1           Full Tree     0.6766             1.0000            0.7333  (28, 22, 30, 115)\n",
       "2         Pruned Tree     0.7631             0.8030            0.8718   (27, 23, 2, 143)\n",
       "3  GBM (Full) [Final]     0.8228             0.8013            0.8923   (34, 16, 5, 140)\n",
       "4  GBM (Full_removed)     0.7890             0.8395            0.8615   (32, 18, 9, 136)\n",
       "5           GBM (sig)     0.7890             0.8698            0.8615   (32, 18, 9, 136)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "gbm_sig_train_acc = full_gbm_sig_fit.score(x_train, y_train).round(4)\n",
    "gbm_sig_test_acc  = full_gbm_sig_fit.score(x_test, y_test).round(4)\n",
    "gbm_sig_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = full_gbm_sig_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'       : 'GBM (sig)',\n",
    "                          'Training Accuracy' : gbm_sig_train_acc,\n",
    "                          'Testing Accuracy'  : gbm_sig_test_acc,\n",
    "                          'AUC Score'         : gbm_sig_auc,\n",
    "                          'Confusion Matrix'  : (gbm_sig_tn,\n",
    "                                                 gbm_sig_fp,\n",
    "                                                 gbm_sig_fn,\n",
    "                                                 gbm_sig_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1a6e2bb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T21:32:30.946579Z",
     "start_time": "2021-12-05T21:32:30.944428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 6.78459906578064 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "263.011px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
